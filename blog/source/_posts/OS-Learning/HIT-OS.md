---
title: "[HIT-OS]哈工大操作系统Notes"
date: 2023/5/06
categories:
- Operating System
tags: 
- Foundation
---

# 1. 操作系统的引导
## 1) bootsect载入OS

1. PC刚开机时，CPU处于实模式，这个模式下CPU按照`CS<<4 + IP`的形式寻址，此时`CS:IP`指向`0xFFFF0`,即存储在ROM上的BIOS程序，于是CPU自动执行BIOS程序，这段程序首先检查硬件设施，接着从磁盘读入首扇区（主引导扇区-Master Boot Record-MBR，共512个字节）到内存`0x07c00`处，并设置`CS:IP`指向这个地址

![](attachment/68c822853ca0f63de658940ba09b7003.png)

2. CPU开始执行MBR的程序，即`bootsect`(作用：将磁盘上的操作系统读入内存，计算机本质上是CPU取指执行，要让操作系统发挥作用，首先得把它加载到内存上)**，**这段程序先将自己（整个首扇区256 words）转移到新地址`0x90000`处（目的在于腾出位置存放操作系统，原因在于防止后续移动操作系统覆盖了`setup`），并跳转到该新地址处继续执行后面的指令

![](attachment/8f19c8e6410929f9f8eadf10f37a2ccd.png)

3. 后续指令从磁盘的第2个扇区开始读入四个扇区(扇区从1开始编号，也就是说读取首扇区后面的四个扇区，即`set-up`模块)到`0x90200`处，即首扇区之后

![](attachment/8f19c8e6410929f9f8eadf10f37a2ccd.png)

4. 读入setup模块后，在屏幕上打印一段信息：`"Loading system ..."`，`es:bp`指向字符串的起始位置，`cx`存储要打印的字符数信息，然后读入`system`模块(也就是操作系统主体)，至此`bootsect`执行完毕，操作系统被从磁盘读入了内存，接着CPU开始执行`setup`

![](attachment/dd5ff3c83ce1679eab6d51fba602f527.png)
![](attachment/848f00e31ae9e6e18106b6038356b61c.png)
## 2) setup建立OS

1. 操作系统要想掌控计算机就需要先知道计算机的基本信息 ，于是`setup`首先通过系统调用获取计算机内存大小（扩展内存：RAM中高于1MB的部分），并将这一信息放在地址`0x90002`处。接着`setup`将`system`模块移动到内存`0x0`处，该模块将一直占用从`0x0`开始的这段内存

![](attachment/19429a3d7d01b10593c4e4448702d955.png)

2. 接着CPU显然就该开始执行`system`模块了，`setup`通过`jmpi 0, 8`这条指令跳转到`system`模块，但是在这之前，`setup`要完成CPU从实模式到保护模式的切换，本质上就是将寻址模式由`segment:offset`16位寻址模式(`cs<<4 : ip`，寻址范围：1MB)，转变为这样一种32位寻址模式（寻址范围4GB）：CS不再是段寄存器，而是一个段选择子，表示的不再是段地址，而是表示一个在GDT（全局描述符表）中的表项的位置，每个表项是64位但能抽取出一个32位的段地址，将该地址与ip（此时变为32位ip，之前是16位）相加后，得到最终地址。`setup`完成这样的转换的方法是将`cr0`寄存器的最后一位置0。至此，`jmpi 0, 8`不再被解释为`jmp 0x80`而是解释为`jmp 0x0000`，于是CPU开始执行`0x0`地址开始的`system`模块 （注意下图的DPL，在后续讲用户态-内核态时会用到）

**旁注:**
> CS 寄存器的值实际上是一个 16 位的段选择子，它指向了一个描述代码段的段描述符，该段描述符中包含了代码段的起始地址、大小、特权级别等信息。当 CPU 执行代码时，会根据 CS 寄存器中的段选择子和段描述符来确定代码段的位置和访问权限

![](attachment/82696a312b38b2caffbed1decdebe663.png)
![](attachment/c8c8680d6369eb064a9fb0434b0b3d31.png)
## 3) head初始化OS

1. 这里的初始化指的是OS为管理各种计算机硬件如内存而初始化多个数据结构，以掌控这些硬件信息，在步入`head`之前，我们应当思考一个问题，那就是操作系统内核是由许多文件组成的，内核编译后形成`image`，`image`就是一个`bootsect-setup-system`结构的二进制文件，叫做内核映像，把这个内核映像放在一个计算机磁盘的首扇区便可以如前文那样启动操作系统，那么内核编译是如何保证`bootsect.s`编译得到的`bootsect`置于`image`文件的首部呢，如何保证`bootsect-setup-system`这样的结构呢？而且`system`模块内也有很多可执行文件，其中位于第一部分的就是由`head.s`编译得到的`head`，如何保证`head`位于`system`的头部呢？     答案是利用`MakeFile`工具，这里简单叙述一下`MakeFile`：
> MakeFile是一个用于自动化构建程序的工具。它是一个文本文件，其中包含了构建程序所需的指令和依赖关系，它可以使用依赖关系来控制编译的顺序。如果某个目标文件依赖于其他文件，那么在编译这个目标文件之前，需要先编译它所依赖的文件。可以使用依赖关系来控制编译的顺序。如果某个目标文件依赖于其他文件，那么在编译这个目标文件之前，需要先编译它所依赖的文件。

![](attachment/cc9b4103bc02a8d67f35043fedfface7.png)
       因此通过利用`MakeFile`我们可以控制在编译结果中各部分的先后顺序

2. `head`完成一些初始化的操作，如初始化GDT（用于寻址，`setup`部分只是为了跳转到`system`而部分初始化了该表）, IDT（用于调用中断处理程序，只是创建一个空的 IDT 表，还未填入中断门等内容），页表。`head`部分与之前的`bootsect`和`setup`在汇编语言上也不同，由于CPU从实模式转换到保护模式，因此`head`由32位汇编语言构成，`ax`变为`eax`，汇编指令也从intel 8086格式转变为AT&T格式

![](attachment/9fe1343ecdbd946c3404a678738f74d7.png)
![](attachment/ba11b3ecaddba2f5b95962aa2edd2a17.png)

3. `head`在设置完页表后会跳转到`main`，这个函数由`main.c`文件编译得到，跳转方式利用了函数调用的栈机制：`head`先压入`main`的地址，在执行`ret`后，栈中弹出该地址赋给`cs:ip`，CPU跳转到`main`开始执行。`head`在压入`main`之前压入了`L6`，这样做会导致从`main`返回后系统进入`L6：jmp L6`的死循环，计算机就会死机，因此`main`函数永远不会返回

![](attachment/9fe1343ecdbd946c3404a678738f74d7.png)
## 4) main继续初始化OS
`main`继续完成初始化OS的操作（包括设置中断门填充IDT表：`trap_init`，`sched_init`），这里主要讲一下对内存的初始化，OS用数组管理内存，对每个字节，OS用`0`表示该字节空闲（内存位图BitMap），从`mem_init`部分的代码可以看出这里使用了之前`setup`初始化的计算机内存大小信息，并以一个页（4K）为单位初始化内存信息
![](attachment/33260348d45935dfc16fd4da8e94e9a0.png)
![](attachment/d0b5436e3bd694ef9dadbf62a885e8f4.png)![](attachment/49e195de46edde2a13a3d612e3f4436f.png)

---

# 2. 彻底理解系统调用
## 1）OS接口的本质是OS提供的函数
无论用户是通过命令行还是图形界面来操作计算机，本质上都是在运行C语言程序，而这些C语言程序不同于普通的C语言程序的点在于它们调用了特殊的函数，即OS提供的函数，去完成特定的任务，如用`fork`函数创建一个进程，用`open`函数打开一个文件。因此这些C语言程序与OS打交道的方式就是这些函数调用，进而完成对计算机硬件的操作，所以我们可以得出OS提供给用户的接口就是这些特殊的函数，用户通过函数调用来使用它们。这里的函数调用有另外的术语，叫系统调用（system call）
> 系统调用（System call）是操作系统内核提供给应用程序使用的一组编程接口，它们允许应用程序请求操作系统内核执行某些特权操作，例如读写文件、创建进程、网络通信等。应用程序可以通过系统调用与操作系统内核进行交互，从而获得操作系统提供的各种服务和资源。
> 系统调用通常是操作系统内核提供的一组函数或指令，应用程序可以通过调用这些函数或指令来请求操作系统内核执行某些操作。系统调用的实现通常是由操作系统内核提供的一组中断服务例程或系统调用门（System Call Gate）来完成的。当应用程序发起系统调用时，操作系统内核会根据系统调用号来确定要执行的操作，并在内核态下执行相应的操作，最后将结果返回给应用程序。

## 2）DPL-CPL机制分离用户态和内核态
系统调用之所以不同于普通的函数调用，就在于它能执行其它函数所不能执行的操作，如访问在OS内核（地址`0x0`开始的那段内存）的数据，那为什么普通函数不能直接访问OS内核呢？这源自于OS内核所在的内存叫内核段（对应内核态），应用程序所在的内存叫用户段(对应用户态)。之前我们提到过的`GDT`，`head`阶段在初始化它时，会将所有内存段（代码段，数据段）的信息写入`GDT`，其中就包括内存段的`DPL(Descriptor Privilege Level)`信息，该信息表示各内存段的的优先级。对于OS内核所在的内存段，`DPL`是`0`，也就是最高优先级。对应用程序所在的内存段，`DPL`是`3`，也就是最低优先级。
讲到这里，我们已经知道了应用程序和OS内核所在的内存段的优先级不同（称前者在用户段，后者在内核段），且该信息由`DPL`记录并保存在`GDT`这一数据结构中。那么要实现这两个态的隔离，即用户段不能访问优先级高于它的内核段，要涉及`CPL`的概念：
> CPL 表示当前代码的运行特权级别。在执行代码时，CPL 将根据代码段描述符中的 DPL 来设置。如果 CPL 等于或高于代码段描述符中的 DPL，则允许代码执行。否则，就会发生“General Protection Fault”（GPF）异常，导致程序终止。

也就是说，当CPU在执行应用程序时，CS:IP指向用户段的指令，CPU根据当前代码段的DPL设置`CPL`（CS的最后两位）为`3`。如果应用程序此时要访问OS内核，那么CPU会先比较CS中的`CPL`和描述OS内核优先级的`DPL`，如果`DPL>=CPL`则说明目标代码段的优先级不如当前代码段的优先级高，可以直接访问，但是在这里`0>=3`不成立，所以不可以直接访问。以上机制均是由计算机硬件实现。既然用户段不能访问内核段，但用户段又有这个需求，所以才有了系统调用，给了用户段间接访问内核段的途径
![](attachment/613a60198a2c9acd2ef05b06c201e63c.png)
## 3）进入内核: int 0x80 中断
在用户程序中使用的系统调用，如`fork`，`open`等函数，本质上是一段含有中断的代码，这个中断指的就是`int 0x80`中断指令，执行这条指令能够让CPU从用户态转换到内核态。现在用一个例子来更详细的说明：
我现在编写了一个C程序并在里面调用了`open`函数，CPU执行`open`函数内部的`int 0x80`指令就会引发`0x80`号中断，然后OS就会根据中断向量号`0x80`查找中断向量表进而执行相应的中断处理程序。`0x80`号中断对应的中断处理程序是专门用于处理系统调用的，这个程序完成这样一件事情：根据传入的`open`这个系统调用的系统调用号（在`%eax`中）查找相应的系统调用处理函数，并转去执行该函数完成打开文件操作，并将结果返回给用户程序。
![](attachment/60e7bd6e50d50fb77b707637148c0e04.png)
![](attachment/d363fbe15afd12811daeb0a66ede9589.png)
可见，一个系统调用完成的特定操作本质上是OS内核中的对应的系统调用处理函数完成的。它之所以是一个面向用户的接口，就在于虽然用户不能像普通函数调用那样直接调用它，但用户可以通过`int 0x80`对应的中断例程和传递系统调用号给`0x80`号中断例程（已经打包在系统库里的接口函数中，因此我们只用直接调用`open`函数即可，而不用编写包含`int 0x80`指令并传递系统调用号参数的程序）进而在该中断例程中完成对系统调用处理函数的调用
**旁注: 系统调用号**
> 系统调用号（System Call Number）是一个与特定系统调用相关联的唯一整数，用于在用户程序和操作系统内核之间标识和调用特定的系统调用。每个系统调用都有一个与之对应的系统调用号。当用户程序需要请求操作系统的服务时，它会通过将系统调用号传递给内核来指明需要执行哪个系统调用。
> 以下是系统调用号的一些基本概念：
> 1. 分配：操作系统为每个可用的系统调用分配一个唯一的系统调用号。这些号码通常是连续的整数，从0开始。
> 2. 查找：当用户程序需要调用某个系统调用时，它需要知道相应的系统调用号。这些号码可以在操作系统的文档或头文件（例如，对于Linux系统，可以查看unistd.h）中找到。
> 3. 使用：用户程序通过将系统调用号和其他必要的参数传递给内核来发起系统调用。这通常通过使用特殊的指令（如x86架构上的int指令）触发软件中断来实现。
> 4. 内核处理：内核收到系统调用请求后，会根据系统调用号查找相应的处理函数并执行。处理函数完成请求后，将结果返回给用户程序。
> 
系统调用号充当了用户程序和操作系统内核之间的接口，使得用户程序能够以一种可靠且一致的方式请求操作系统的服务。

**旁注：软中断与硬中断 **
> 内中断和外中断是计算机系统中两种不同类型的中断。它们的主要区别在于中断的来源和触发方式。
> 1. 内中断（内部中断）： 内中断是由处理器内部的事件或程序执行过程中出现的异常触发的。它们通常与正在执行的指令或处理器的状态有关。内中断的常见类型包括：
> - 软件中断：由特定的指令（如x86架构上的int指令）在程序中显式触发的中断。**软件中断通常用于实现系统调用，让用户程序能够请求操作系统的服务。**
> - 陷阱（Trap）：在执行某些特定指令时自动触发的中断。陷阱用于处理特殊情况，如整数除以零、浮点数溢出或无效指令等。
> - 断点（Breakpoint）：用于调试程序的一种中断。当程序执行到某个预先设置的断点时，处理器会触发一个中断，允许调试器检查程序的状态。
> 2. 外中断（外部中断）： 外中断是由处理器外部的硬件设备发出的信号触发的。它们通常与外部事件或设备的状态变化有关。当一个硬件设备需要处理器的注意时（例如，读取数据、处理错误或通知状态改变），它会发送一个中断请求（IRQ）信号给处理器。处理器会在适当的时机响应这个中断请求，暂停当前的任务并执行相应的中断处理程序。外中断的常见类型包括：
> - I/O设备中断：由外部输入/输出设备触发，如键盘、鼠标、硬盘等。
> - 计时器中断：由系统计时器触发，用于实现多任务调度、时间管理等功能。
> - 电源管理中断：由电源管理系统触发，用于处理电源相关事件，如电池电量低或休眠唤醒等。
> 
总之，内中断与外中断的主要区别在于它们的来源：内中断由处理器内部的事件或异常触发，而外中断由外部硬件设备发出的信号触发。不过，无论是内中断还是外中断，处理器在接收到中断信号后都会执行相应的中断处理程序，以处理中断事件。

**旁注：中断类型码与中断向量号**
> 1. 中断类型码：中断类型码是一种用于区分不同类型的中断和异常的编码。在x86架构中，常见的中断类型码有如下几种：
>    - 外部中断（硬件中断）：由外部设备（如键盘、鼠标、定时器等）产生的中断。
>    - 软件中断：由程序主动触发的中断，例如通过int指令（在x86架构中）。
>    - 异常：由处理器在执行指令时检测到的错误或异常条件引发的中断，如除以零、非法操作码、内存访问越界等。
> 2. 中断向量号：中断向量号是一个唯一标识中断源的整数，用于在中断向量表（实模式下）或中断描述符表（保护模式下）中索引到对应的中断处理程序。中断向量号通常与中断类型码相关联，例如在x86架构中，一个设备的外部中断请求（IRQ）可能会被映射到一个特定的中断向量号。
> 3. 中断号：中断号通常是指中断向量号，它是一个整数，用于唯一标识中断源。在实际应用中，中断号和中断向量号这两个术语通常可以互换使用。
> 
总之，中断类型码用于区分中断的类型（硬件中断、软件中断或异常），而中断向量号（中断号）则用于在中断处理表中唯一标识和索引到对应的中断处理程序。

## 4）从printf函数出发到int 0x80
### 1. 迈向int 0x80：printf函数内部
首先，我们查看`printf`的内部。以下是一个基于GNU C库的`printf`函数的简化实现，以展示其内部机制：
```c
#include <stdarg.h>
#include <stdio.h>
#include <unistd.h>

int printf(const char *format, ...) {
    va_list args;
    int done;

    va_start(args, format);
    done = vfprintf(stdout, format, args);
    va_end(args);

    return done;
}

int vfprintf(FILE *stream, const char *format, va_list ap) {
    int written = 0;
    char buffer[1024];

    //调用vsnprintf将可变参数转化为字符数组格式
    int len = vsnprintf(buffer, sizeof(buffer), format, ap);
    if (len < 0) {
        return -1;
    }

    //将字符数组写入标准输出流
    written = write(STDOUT_FILENO, buffer, len);
    if (written != len) {
        return -1;
    }

    return written;
}

```
`printf`函数本身只是将可变参数封装到`vfprintf`函数中，并将标准输出流`stdout`作为参数传递给`vfprintf`。`vfprintf`函数负责将可变参数格式化为一个字符数组，并将该字符数组写入标准输出流。在该函数中，我们看到它调用了`vsnprintf`函数来将可变参数格式化为字符数组，并使用`write`系统调用将该字符数组写入标准输出流中。
在`vfprintf`函数中，`vsnprintf`函数将可变参数转换为字符数组格式，并将其存储在`buffer`数组中。然后，`write`系统调用将该字符数组写入标准输出流中，使用文件描述符为`STDOUT_FILENO`（等同于标准输出流）。当`write`系统调用返回时，它返回写入的字节数。
### 2. 迈向int 0x80：write函数内部
那么`write`系统调用背后又是什么样呢？让我们来查看`write`函数的内部
```c
#define __LIBRARY__
#include <unistd.h>

_syscall3(ssize_t, write, int, fd, const void*, buf, size_t, count); 

```
在理解了宏函数`_syscall3`之后可以看出，这里的`_syscall3`宏展开之后便是一个返回值为`int`的`write`函数
### 3. 迈向int 0x80：_syscall3宏函数
一步一步来，接着我们查看`_syscall3`宏函数的定义
```c
#define _syscall3(type,name,type1,arg1,type2,arg2,type3,arg3) 
type name(type1 arg1,type2 arg2,type3 arg3) \
{ \
long __res; \
__asm__ volatile ( \
"int $0x80" \
: "=a" (__res) \
: "0" (__NR_##name),"b" ((long)(arg1)),"c" ((long)(arg2)), \
"d" ((long)(arg3))); \
__syscall_return(type,__res); \
}

```
我们逐行的解析`_syscall3`宏函数：
```c
#define _syscall3(type,name,type1,arg1,type2,arg2,type3,arg3)
```
预处理器指令` #define`将宏`_syscall3` 定义为一个具有八个参数的宏函数，即将`_syscall3`映射为后续的代码块。如果程序中出现该宏定义（write函数内部），那么将在编译预处理阶段被替换为后续的代码块。
其中，各参数的含义如下：

- type：定义系统调用的返回值类型，如 int、long 等。
- name：定义系统调用的名称，如 open、read 等。
- type1、type2、type3：定义系统调用的参数类型。
- arg1、arg2、arg3：定义系统调用的参数名称。
```c
type name(type1 arg1,type2 arg2,type3 arg3)
```
这是 `_syscall3` 宏定义中的第二行，它定义了一个函数，该函数的名称为 `name`，它有三个参数 `arg1`、`arg2` 和 `arg3`，它的返回值类型为 `type`。这个函数是系统调用的入口点，它将通过汇编指令触发系统调用，并返回系统调用的结果。
```c
{ \
    long __res; \
    __asm__ volatile ( \
        "int $0x80" \
        : "=a" (__res) \
        : "0" (__NR_##name),"b" ((long)(arg1)),"c" ((long)(arg2)), \
          "d" ((long)(arg3))); \
    __syscall_return(type,__res); \
}
```
这是 `_syscall3 `宏定义中的其它部分，它是 `name` 函数的函数体，其中使用了嵌入式汇编语言。宏函数的传入参数要用括号括起来，保证宏展开后运算的正确性。
函数体中的第一行定义了一个 `long` 类型的变量 `__res`，用于存储系统调用的返回值。变量名前面的双下划线是为了避免与用户定义的变量名冲突。
第二行使用了 `asm` 关键字定义了一个内联汇编代码块，它使用了 `volatile` 关键字，告诉编译器不要对代码进行优化。在汇编代码中，使用了 `int $0x80` 指令触发系统调用，接着的两个冒号是给`int $0x80`传参，其中的`_NR_##name` 是一个宏，`## `运算符是一种预处理器运算符，它用于将两个标识符连接成一个新的标识符。在这里，它将`_NR` 和 `name` 连接起来，得到宏`_NR_write`,这个宏定义在`<unistd.h>`的开头），它将 `name` 参数转换为系统调用的编号（即数字4，这就是系统调用号）并赋给寄存器`%eax`。
![](attachment/7e450d69c1d03c9011f11f0b067acb76.png)
在 `_syscall3` 宏定义中，asm 内联汇编语言块中使用了冒号（:）运算符来指定输入操作数（Input Operand）和输出操作数（Output Operand），操作数的格式为 `"constraint" (C expression)`。
其中，`constraint` 是操作数的约束符，用于指定操作数应该存放在哪个寄存器或内存位置，`C expression` 是操作数的 C 语言表达式，用于指定操作数的值。
在这里，`"=a"`、`"0"`、`"b"`、`"c"` 和 `"d"` 都是操作数的约束符，它们的含义如下：

- "=a"：表示将返回值存放在寄存器 eax 中。
- "0"：表示将系统调用号存放在寄存器 eax 中。
- "b"：表示将第一个参数的值存放在寄存器 ebx 中。
- "c"：表示将第二个参数的值存放在寄存器 ecx 中。
- "d"：表示将第三个参数的值存放在寄存器 edx 中。

`int 0x80 `指令执行时，会将 `eax` 寄存器中的值作为系统调用号，`ebx`、`ecx`、`edx` 寄存器中的值分别作为系统调用的第一个、第二、第三个参数。因此，要向` int 0x80` 指令传递参数，可以将参数存储在寄存器中，然后通过 asm 内联汇编语言块传递给 `int 0x80` 指令。
这些约束符在汇编代码中对应的位置使用了百分号（%）符号进行引用，如 %0 表示第一个操作数，%1 表示第二个操作数，以此类推。在这个例子中，"%0"、"%1"、"%2"、"%3"、"%4" 分别对应返回值、系统调用号、第一个参数、第二个参数和第三个参数。
![](attachment/a2c1f6510d1747ac9f31f9caaa5f0cf6.png)
### 4. 步入int 0x80：中断门
中断门(gate)是IDT表的一个表项的内容，代表了一个中断处理程序的段选择子和偏移地址（即中断入口地址），它包含以下信息：
> - 中断服务程序的段选择器
> - 中断服务程序的偏移地址
> - 一些标志位，如特权级（DPL）和类型（如任务门、中断门、陷阱门等）

当发生中断或异常时，处理器会根据中断向量号在中断描述符表（IDT）中查找相应的中断门，然后跳转到关联的处理程序进行处理。
这个IDT表很像我在学习实模式汇编时遇到的中断向量表，这两个表有如下关系，因为操作系统在引导阶段就以及步入了保护模式，因此我们用到的都是IDT表（实模式是早期计算机中的一种工作模式，现已逐渐淘汰）
> 1. 中断向量表：中断向量表是实模式下（16位）用于存储中断处理程序入口地址的表。它通常位于内存的低地址（例如0x0000）。在实模式下，每个中断向量占用4个字节，前两个字节是段地址，后两个字节是偏移地址。中断向量表的大小是固定的，共有256个向量，因此占用1KB（1024字节）的内存空间。
> 2. IDT表：IDT表（中断描述符表）是保护模式下（32位或64位）用于存储中断门和异常门描述符的表。IDT表的每个条目包含了处理程序的段选择子、入口地址、特权级和类型等信息。与实模式下的中断向量表不同，IDT表的大小是可变的，可以根据需要设置表的大小和地址。

因此要执行`int 0x80`的中断处理程序，首先就要得到它的中断门。我们在引导过程的时候已经提到过，IDT表在`head`阶段初始化，在`main`阶段填充正确的值。下面展示了OS到底是如何初始化0x80号中断的中断门：

1. `main`阶段调用`kernel/sched.c`中的`sched_init`函数，该函数内调用了`set_system_gate(0x80, &system_call)`，`&system_call`代表了中断处理程序地址

![](attachment/d363fbe15afd12811daeb0a66ede9589.png)

2. `set_system_gate`是`include/asm/system.h`文件中的一个宏函数，用于设置系统调用（0x80号中断）的中断门。从这个宏函数的定义可以看出，它又调用了`_set_gate`函数

![](attachment/7e450d69c1d03c9011f11f0b067acb76.png)

3. `_set_gate`也是`include/asm/system.h`文件中的一个宏函数，它用于设置各种门描述符，包括系统调用中断门。`_set_gate` 接受四个参数：`gate_addr`（中断门描述符在 IDT 表中的地址）、`type`（门类型）、`dpl`（特权级）和 `addr`（中断处理程序的地址，这里是`&system_call`），并根据这些参数设置门描述符。

![](attachment/532ab5bef0f2b1fbcb4e3a75616980cc.png)
`_set_gate`看起来挺复杂，其实就做了这样几件事：在IDT表项中填入了中断处理程序`system_call`的入口地址，设置段选择子为8（CS，对应段地址 0)，DPL为3。
**旁注：OS中，什么是描述符**
> 在操作系统中，描述符是一种数据结构，它提供了关于内存段或系统资源（如文件、设备等）的元数据。在x86架构的保护模式下，描述符的主要作用是对内存段进行描述，以支持内存保护和虚拟内存管理。描述符通常存储在描述符表（例如，全局描述符表 GDT 或局部描述符表 LDT）中。
> 描述符中包含的信息有：
> 1. 基地址：内存段的起始地址。
> 2. 段限长：内存段的大小，通常以字节数表示。
> 3. 访问权限：段的读/写/执行权限。
> 4. 特权级：指定内存段的特权级别（0-3）。在x86架构中，有4个特权级，其中0级为最高特权级，3级为最低特权级。
> 5. 段类型：段的类型，例如数据段、代码段等。
> 6. 存在标志：表示描述符是否有效。
> 
描述符在操作系统中扮演着关键角色，主要用于内存管理、进程隔离以及处理程序调用（例如，系统调用、中断和异常处理）。描述符提供了一种抽象层，使得操作系统能够对内存和其他系统资源进行更精细的控制。
> 在理解描述符时，我们可以将其看作是一组存储了某个对象或资源的信息的数据结构，例如内存段描述符存储了一个内存段的起始地址、大小、访问权限、特权级等信息。这些信息可以被操作系统或处理器用于执行相应的操作，例如访问内存、执行代码等。
> 然而，描述符并不是指针。描述符存储的信息是直接编码在描述符的字段中，而不是存储在某个内存位置上并使用指针进行访问。在x86架构中，段描述符和门描述符的格式和编码规则是由处理器规定的，不同类型的描述符具有不同的字段和编码方式。
> 当处理器需要使用某个描述符时，它会从描述符表（GDT或LDT）中读取相应的描述符，然后使用其中的信息执行相应的操作。例如，当需要访问一个内存段时，处理器会从GDT或LDT中读取该内存段的描述符，并使用其中的信息计算出内存段的物理地址，然后进行访问。
> 因此，描述符是一种用于存储某个对象或资源的信息的数据结构，与指针不同，它不是用于访问内存位置的工具，而是用于提供某个对象或资源的信息的编码方式。

**旁注：什么是门描述符**
> 在x86架构中，IDT（中断描述符表）的每个表项占用64位。表项的结构称为门描述符。门描述符定义了一个中断或异常处理程序的入口点、特权级别以及其他相关信息。根据处理程序的类型和特权级别，门描述符可以表示中断门、陷阱门或任务门。
> 门描述符的结构如下：
> ![](attachment/60e7bd6e50d50fb77b707637148c0e04.png)
> 总之，IDT表项是64位，包含了门描述符的信息。门描述符定义了中断或异常处理程序的入口点和相关属性。中断门是门描述符的一种类型，用于处理硬件和软件中断。

### 5. 步入int 0x80：从用户态到内核态
上一步我们说了`0x80`号中断门的设置过程，最后该中断门(描述符)的`DPL`字段被设置为`3`。操作系统在用户程序中执行`int 0x80`试图跳转到内核的中断程序程序时，CPU检查此时的`CPL`为`3`，目标代码段的`DPL`也为`3`，此时满足`DPL>=CPL`，因此可以从用户段跳转到内核段。接着，根据中断门中的段选择子设置CS，偏移地址设置IP。注意，因为段选择子是`8(1000)`,因此CS的最后两位被设置为0，即`CPL`又被设置为0，符合系统初始化时为OS内核段设置的优先级。由此可见之所以专门将`0x80`号中断用于系统调用，就在于其中断处理程序描述符的`DPL`为3，因此提供给用户一个契机进入内核，并在进入内核后，将`CPL`修改为0
### 6. int 0x80中断处理程序：system_call
最后一步，CPU开始执行中断处理程序`system_call`，该函数先通过一个函数表（函数指针表）`_sys_call_table`调用处理函数`sys_write`完成写入的操作（这个才是整个系统调用过程中真正实现功能的部分，涉及内存）。这里的`_sys_call_table(,%eax,4)`中的`%eax`是中断向量号，加上4倍偏移是因为在函数表`_sys_call_table`中每个函数的地址（函数指针）占4个字节。
至此，我们基本完成了printf函数的系统调用过程
![](attachment/e6d3379fc4d365ff408c77b2babf4d21.png)
![](attachment/e01a62cd2c34aaab94c959af6be846d3.png)![](attachment/532ab5bef0f2b1fbcb4e3a75616980cc.png)

---

# 3. 多进程与多线程
本章主要先讲述线程，因为线程不涉及内存的切换，通过线程切换将执行序列的切换（主要是栈）讲清楚之后，再通过在linux0.11环境下执行fork中断的实际例子看进程的切换
## 1）多进程是为了充分利用CPU
给CPU设置一个PC值，它便可以执行程序，如果CPU在执行程序中途遇到`I/O`操作，那么它在`I/O`结束之前将无法继续执行下一步指令。因此出于管理好CPU就是充分利用CPU的准则，CPU应当离开当前进程，转而去执行其它进程，在`I/O`结束后（且CPU空闲）时再返回继续执行该进程
这一过程涉及了多进程，计算机中有多个进程在跑，即并发（同时出发，交替执行）。为了完成进程间的切换，OS应当记录进程切换时的状态以便在返回时可以正确的继续执行，这些进程的状态记录在进程的PCB（一个结构体）中。进程区别于程序最大的一点就在于OS需要记录进程的状态，而对程序不需要
## 2）OS用 PCB+队列+状态 管理多进程
PCB记录单个进程的信息，OS将多个进程的PCB根据进程状态组织成队列，如就绪队列，等待队列，以及正在执行的单个进程
![](attachment/e36a2a99955dab7372f26e5f6c54cea0.png)
![](attachment/172349e0413d8582ce691ac2f1abecf3.png)
## 3）多进程的要素：调度算法，切换过程，内存隔离，合理的推进顺序
①调度算法用于CPU交替执行进程时选择下一个进程 ②进程的切换，要从进程A切换到进程B，那么先保存当前CPU中的各个值到进程A的PCB中，再将进程B的PCB各值载入CPU ③如果各进程间的内存不独立，那么一个进程运行时就可能修改另一个进程的数据，造成错误，因此各进程要使用不同的映射表以将同一逻辑地址映射到不同的物理地址，形成内存隔离 ④ 进程的合作，典型的就是消费者-生产者的例子，要保证合作正确，要求进程间有着合理的推进顺序
![](attachment/840754c4bede736bec5534802d03b4c2.png)
## 4）多线程提高了进程的执行速度和响应度
进程由指令序列和资源（如内存，网络连接等）组成，线程就是一个进程中的一部分执行序列。因为一个进程中的多个线程间共享资源，因此在线程间切换时仅涉及指令序列的切换（对用户级线程，就像函数调用），进而较之进程间的切换，线程间的切换速度更高。多线程能够提高进程的执行速度，当进程的一个线程 (内核级线程) 先入`I/O`操作时，可以切换到另一个线程继续利用CPU，同时，多线程 (内核级线程) 还可以利用多核CPU（多个处理器，同一内存映射）的优势，使得多个线程可以在不同的CPU核上并行执行，从而进一步提高系统的并发度和效率。多线程还能提高进程的响应度，比如网页的加载，加载文字的进程执行好了就切换到显示进程，而不是等文字图片视频全部加载好了再执行显示进程。过多的线程会导致线程切换的开销增大，从而降低系统的效率，因此线程的数量也是一个_trade-off _问题
## 5）2个用户级线程：2个栈，2个TCB
用户级线程（ULT）对OS不可见，因此不可访问硬件资源，也不能利用多核CPU（为线程分配处理器硬件，需要线程进入OS内核）
两个栈：对2个用户级线程，如果共用一个栈，那么将可能导致函数返回时CPU转去执行另一个线程，而不是通过我们的`Yield`函数，这会造成意料之外的错误。为每个线程分配一个栈（栈顶信息保存在TCB中），那么在一个线程中由函数调用导致的地址返回将不会跳出本线程。
`Yield`函数：该函数要实现线程间的切换，直观的可能认为该函数内部应该有`jmp`指令实现跳转，但实际上该函数并不存在该指令，而是通过函数返回机制实现跳转，当`Yield`函数结束时，栈中弹出的返回地址就已经是进程2的了，`CS:IP`被赋值为该地址，由此CPU转到进程2执行，因此该函数内部仅有两个线程栈的切换
```c
void Yield()
{
    TCB1.esp = CPU.esp;
    CPU.esp = TCB2.esp;
}
```
即更新当前线程的栈顶值并保存到该线程的TCB中，并将下一个线程的栈顶值赋给CPU中的`%esp`，`Yield`函数结束返回时完成跳转
![](attachment/a660c4c01c2033e2876e3574083862bd.png)
`ThreadCreate`函数：要创建一个线程，就要分配给它需要的TCB，栈，并将栈顶信息存储在TCB中，以及将函数入口地址压入栈
```c
void ThreadCreate(A) // A is function address
{
    TCB* tcb = malloc();   // allocate TCB
    *stack = malloc();  // allocate stack
    *stack = A ;
    tcp.esp = stack;  // store stack pointer
}
```
**旁注：TCB与PCB的区别**
> 在操作系统中，TCB（Thread Control Block，线程控制块）和PCB（Process Control Block，进程控制块，在进程表中）是分别管理线程和进程的数据结构。以下是两者之间的区别：
> TCB（线程控制块）：线程控制块是一个数据结构，用于存储有关进程中单个线程的信息。线程是进程中的轻量级、独立执行路径，共享同一地址空间和资源。TCB通常包含以下内容：
> 1. 线程ID：分配给线程的唯一标识符。
> 2. 线程状态：线程的当前状态（例如就绪、运行、等待或已终止）。
> 3. 程序计数器：线程将执行的下一条指令的地址。
> 4. CPU寄存器：线程上次执行时的CPU寄存器的值。
> 5. 堆栈指针：指向线程在内存中的私有堆栈的指针。
> 6. 调度和优先级信息：关于线程的优先级和调度要求的详细信息。
> 
PCB（进程控制块）：进程控制块是一个数据结构，用于存储有关进程的信息。进程是运行程序的实例，具有自己的地址空间和资源。PCB包含以下内容：
> 1. 进程ID：分配给进程的唯一标识符。
> 2. 进程状态：进程的当前状态（例如就绪、运行、等待或已终止）。
> 3. 程序计数器：进程将执行的下一条指令的地址。
> 4. CPU寄存器：进程上次执行时的CPU寄存器的值。
> 5. 内存管理信息：关于分配给进程的内存的详细信息，包括基地址和限制地址。
> 6. I/O状态信息：关于进程使用的打开文件和I/O设备的信息。
> 7. 调度和优先级信息：关于进程的优先级和调度要求的详细信息。
> 8. TCB列表：线程控制块列表，每个线程对应一个。
> 
总之，TCB管理有关进程中单个线程的信息，而PCB管理有关整个进程的信息，包括所有线程。两者对于操作系统有效地管理和调度进程和线程都是必不可少的。

## 6）2个内核级线程：2套栈，切换的5个步骤
一个内核级线程有一套栈（用户级栈+内核级栈）。内核级栈中压入了用户级栈的`cs:ip`、`ss:sp`以便内核级线程能从内核态返回用户态
KLT就是能进入OS内核的ULT吗？
> 不，内核级线程不是可以进入操作系统内核的用户级线程。内核级线程和用户级线程是截然不同的概念，它们在操作系统中的管理方式也不同。
> 内核级线程（Kernel-level Thread，简称KLT）是由操作系统内核直接管理和调度的线程。内核知道这些线程的存在，并对它们的调度、管理和协调拥有完全的控制权。内核级线程可以属于一个或多个进程，**它们既可以在用户模式下运行（执行用户代码时），也可以在内核模式下运行（执行系统调用或内核代码时）**。
> 另一方面，用户级线程（User-level Thread，简称ULT）是一种由用户空间库管理的轻量级线程，无需内核干预。操作系统并不知道这些线程的存在，所以它们的管理、调度和协调都由用户级库处理。用户级线程在用户模式下运行，只有在进行系统调用时才能进入内核模式，但此时内核并不知道线程上下文本身，而是将整个进程视为一个单元。
> 总之，内核级线程不是可以进入操作系统内核的用户级线程。它们是在操作系统中以不同方式管理的独立实体。

**旁注：ULT和KLT的区别**
> 用户级线程和内核级线程是在操作系统中实现线程的两种不同方法。线程允许任务并发执行，从而更有效地利用系统资源并提高整体系统性能。以下是它们之间的主要区别：
> 1. 管理：
> 
 ○ 用户级线程（User-level Threads，简称ULTs）由用户空间库管理，无需内核干预。这意味着操作系统不知道这些线程的存在，管理、调度和协调都由用户级库处理。
>  ○ 内核级线程（Kernel-level Threads，简称KLTs）由操作系统内核直接管理。内核知道这些线程的存在，并对它们的调度、管理和协调拥有完全的控制权。
> 2. 调度： 
> 
○ ULTs由用户空间库调度，这意味着它们可以有自己的自定义调度策略。**内核不知道这些线程的调度，所以如果一个用户级线程阻塞，可能导致整个进程阻塞**。 
> ○ KLTs由内核调度，内核使用系统范围的策略来确定它们的执行顺序。如果一个内核级线程阻塞，内核可以调度同一进程中的另一个线程，防止整个进程被阻塞。
> 3. 上下文切换： 
> 
○ ULTs的上下文切换开销较低，因为切换发生在用户空间，不需要转换到内核模式。这使得用户级线程的上下文切换更快。 
> ○ KLTs的上下文切换开销较高，因为它们涉及从用户模式到内核模式的转换，然后再返回。这使得内核级线程的上下文切换更慢。
> 4. 可移植性： 
> 
○ ULTs通常具有更好的可移植性，因为它们是通过用户空间库实现的，不依赖于内核级线程支持。这使得它们可以在不同的操作系统上使用，只需进行最少的更改。 
> ○ KLTs的可移植性较差，因为它们依赖于内核对线程的支持，这在不同的操作系统之间可能存在差异。
> 5. 资源共享： 
> 
○ ULTs共享相同的资源，如文件描述符和内存，因为它们属于同一个进程。这使得线程间通信和同步更容易。 
> ○ KLTs可以属于不同的进程，这意味着它们可能拥有独立的资源，使得线程间通信和同步更复杂。
> 总之，用户级线程提供了更好的可移植性和较低的上下文切换开销，但由于内核对它们的调度不了解，它们的调度受到限制。另一方面，内核级线程提供了更好的调度和资源共享，但上下文切换开销更高，可移植性较差。

切换的5个步骤:
线程A_用户栈$\xrightarrow{\text{interrupt}}$线程A_内核栈$\longrightarrow$线程A_TCB$\longrightarrow$线程B_TCB$\longrightarrow$线程B_内核栈$\xrightarrow{\text{iret}}$线程B_用户栈。
![](attachment/257036f48e30c46dedcbdf50015da107.png)
![](attachment/6275de0a9feabb7b06a305b4e04ba190.png)

下面以系统调用`fork()`为中断，详细讲解这个5个步骤
### 1. 从fork()中断开始，用户栈到内核栈
初始状态时，一个用户程序在运行，此时使用它的用户栈。当它在程序中调用系统调用函数`fork()`时，根据前面我们讲解的系统调用背后发生的故事，CPU会转去执行`_syscall*`函数，并会执行到`int 0x80`指令。当CPU开始执行`int 0x80`之前，会将此时的`CS:IP`和`SS:IP`压入内核栈（通过tss找到）中，因为此时`int 0x80`还没开始执行，也就是说，CPU还未跳转到内核段中的中断处理程序`system_call`去执行，因此此时的`CS:IP`和`SS:IP`都是用户程序的，即`SS:IP`指向是用户栈，`CS:IP`指向的是用户程序中`int 0x80`的下一条指令。接着CPU执行`int 0x80`之后，CPU跳转到内核段的`system_call`执行，此时`SS:IP`转变为指向内核栈
![](attachment/a660c4c01c2033e2876e3574083862bd.png)
### 2. 判断阻塞，执行schedule，预置中断出口
CPU开始执行内核函数`system_call`，该函数首先压入一堆寄存器，因为是刚进入内核，因此这些寄存器还是之前用户态的值，这么做的目的是保存用户程序的状态。接着`system_call`通过查找函数表`_sys_call_table`调用`sys_fork`函数。执行完`sys_fork`函数之后，OS通过检查该线程PCB的`state`变量是否为`0`判断该线程是否变为阻塞态 或 该线程的时间片是否用完，再决定是否执行调度（schedule）
![](attachment/97bcb18bfbfeb7e9317be7ad13681c7d.png)
![](attachment/02e77af27b1c4e865e36db8907ca7b63.png)
在`reschedule`函数中，先压入了包含`iret`指令的代码段的起始地址（标号：`ret_from_sys_call`）作为中断出口，然后跳转到`schedule`函数（位于`kernel/sched.c`）执行调度，即执行5段论的中间3段
![](attachment/6275de0a9feabb7b06a305b4e04ba190.png)
![](attachment/42cd427d395bd0887302dfbe5f3a095f.png)
### 3. 执行切换，过时的硬件切换-TSS机制和现代的软件切换-TCB机制
在`schedule`函数中调用了`switch_to(next)`函数（位于`include/linux/sched.h`）用于完成切换5段论的中间三段，这里的`next`是根据调度算法选择的另一个进程的PCB（linux0.11没有线程的概念，因此这里称进程）。
![](attachment/d198271aa8a29539467dd82ee47ef6ad.png)
在linux-0.11中，线程切换使用了TSS机制：
![](attachment/40edff8d78bfb0c20b5b843703546e03.png)
关于TSS, 进行几点说明：

1. **TSS实际上就是保存了一堆寄存器值的数据结构，这堆寄存器的值又体现了进程的当前状态**
> 任务状态段（Task State Segment，TSS）是x86架构中用于支持硬件任务切换的一种内存数据结构。TSS包含了与一个特定任务（例如，进程或线程）相关的信息，如CPU寄存器的值、段选择器和其他一些特定于任务的数据。
> 在x86架构中，任务切换可以通过硬件实现，使用任务寄存器（Task Register，TR）指向当前任务的TSS。当发生任务切换时，处理器会自动保存**当前任务的状态**到当前任务的TSS，并从新任务的TSS加载新任务的状态。
> 尽管TSS提供了一种硬件级别的任务切换机制，但它在实际应用中的效率较低，因为硬件任务切换涉及大量的内存访问和处理器操作。因此，许多现代操作系统，包括Linux，选择使用软件任务切换，即使用编程手段保存和恢复任务上下文，而不是依赖硬件实现的TSS机制。

2. **TSS的内容是TCB的子部分**
> 任务状态段（Task State Segment，TSS）是一种用于保存任务（进程或线程）状态的数据结构。然而，TSS是一种特定于x86体系结构的硬件数据结构，用于支持硬件任务切换。它在内存中存储任务的上下文信息，包括寄存器值、特权级等。
> 线程控制块（Thread Control Block，TCB）与TSS有相似之处，但它是一种软件概念，而不是硬件概念。TCB是操作系统用于表示和管理线程的内核数据结构。它通常包括线程上下文（如寄存器值）、线程状态、优先级、调度信息等。与TSS类似，TCB也用于在任务切换时保存和恢复线程的上下文信息。
> 尽管TSS和TCB都涉及保存任务状态信息，但它们在概念上和用途上有所不同：
> 1. 硬件与软件：TSS是一种硬件数据结构，特定于x86架构，用于支持硬件任务切换。而TCB是一种软件数据结构，由操作系统实现，用于管理线程。
> 2. 依赖与通用性：TSS依赖于特定的CPU架构（如x86），而TCB是一种通用的操作系统概念，可以在多种CPU架构上实现。
> 3. 作用域：TSS主要关注任务的硬件状态，例如寄存器值和特权级。而TCB除了保存线程的硬件状态，还包括其他与线程管理和调度相关的信息，如线程状态、优先级等。
> 
总之，虽然TSS和TCB在保存任务状态方面有相似之处，但它们分别代表硬件和软件层面的概念。在现代操作系统中，通常使用软件任务切换（通过TCB）而不是硬件任务切换（通过TSS），因为软件任务切换更加高效且易于维护。

3. **TSS机制下的线程切换**
> 假设我们有两个线程：线程A和线程B，它们各自有一个任务状态段（TSS）。我们将通过x86硬件任务切换机制实现从线程A切换到线程B。以下是使用TSS机制进行线程切换的步骤：
> 1. 为线程A和线程B创建TSS：首先，在内存中分配两个TSS结构，分别用于保存线程A和线程B的状态。每个TSS包含了线程的寄存器值、段选择器等信息。同时，我们需要为每个线程创建一个对应的TSS描述符，并将它们添加到全局描述符表（Global Descriptor Table，GDT）中。
> 2. 设置任务寄存器（TR）：将任务寄存器（TR）设置为当前线程（线程A）的TSS描述符在GDT中的选择器。这告诉处理器当前正在执行的任务的TSS在哪里。
> 3. 准备进行任务切换：为了从线程A切换到线程B，我们需要执行一个特殊的指令（`ljmp`）来触发硬件任务切换。这需要使用线程B的TSS描述符在GDT中的选择器作为操作数。
> 4. 触发硬件任务切换：当处理器检测到这个特殊的指令，它会自动执行以下操作：
>    - 保存线程A的当前状态到线程A的TSS中，包括通用寄存器、段寄存器、标志寄存器、指令指针等。
>    - 更新线程A的TSS中的任务链接字段，使其指向线程B的TSS。这用于在将来返回线程A时进行任务切换。
>    - 将任务寄存器（TR）更新为线程B的TSS描述符在GDT中的选择器。
>    - 从线程B的TSS加载线程B的状态，包括通用寄存器、段寄存器、标志寄存器、指令指针等。
>    - 更新线程B的TSS中的任务链接字段，使其指向线程A的TSS。
> 5. 开始执行线程B：处理器已经完成了从线程A到线程B的任务切换，现在开始执行线程B的代码。
> 
任务链接字段是任务状态段（Task State Segment，TSS）中的一个字段，用于在硬件任务切换过程中保存与当前任务关联的前一个任务的信息。任务链接字段中存储的是前一个任务的TSS选择器，该选择器指向全局描述符表（Global Descriptor Table，GDT）中相应的TSS描述符。这样，在将来需要从线程B切换回线程A时，处理器可以通过线程B的任务链接字段找到线程A的TSS，并完成任务切换。
> 通过以上步骤，我们完成了从线程A切换到线程B的任务切换。需要注意的是，这个过程完全由硬件自动完成，而不需要操作系统通过编程手段来保存和恢复任务状态。然而，正如前面所提到的，硬件任务切换效率较低，因此现代操作系统通常使用软件任务切换机制。

**旁注：iret指令不仅弹出CS:IP**
> iret（中断返回）指令是x86架构中用于从中断或异常处理程序返回的指令。它不仅仅弹出代码段寄存器（CS）和指令指针（IP），而且在中断或异常处理程序返回时会将一些其他重要的寄存器值恢复到原始状态。
> 具体来说，当执行iret指令时，处理器会执行以下操作：
> 1. 弹出标志寄存器（FLAGS）的值，并恢复其内容。
> 2. 弹出代码段寄存器（CS）的值，并恢复其内容。
> 3. 弹出指令指针（IP）的值，并恢复其内容。
> 
在中断和异常处理程序中，处理器还会自动将其他重要寄存器的值压入栈中，例如堆栈段寄存器（SS）和堆栈指针（SP）。在这种情况下，执行iret指令时，处理器还需要从栈中弹出这些寄存器的值。
> **总之，iret指令不仅仅弹出CS和IP，还负责恢复其他相关寄存器的值，从而使处理器能够在中断或异常处理程序结束后继续执行原始代码。需要注意的是，iret指令不会弹出整个函数栈上的所有内容，而只会弹出保存在栈上的这些寄存器值。**
> 现代操作系统使用软件切换，通过如用户级程序那样编程实现：保存当前CPU中的`%esp`值到进程A，将进程B的`%esp`值加载到CPU，通过`ret`弹出进程B内核栈的函数返回地址赋值给IP，而该函数地址（标号：`ret_from_sys_call`）是一段包含`iret`的代码，由此接着CPU会执行到`iret`指令，从进程B的内核栈中弹出用户代码所在的`CS:IP`，状态寄存器`FLAGS`，`SS:IP`，从而切换到进程B的用户代码执行，并且使用的栈也切换为用户栈

![](attachment/40edff8d78bfb0c20b5b843703546e03.png)![](attachment/d198271aa8a29539467dd82ee47ef6ad.png)
## 7）fork函数从父进程创建子进程，关键在copy_process函数
### 1. 进入`copy_process`函数
CPU执行`sys_fork`函数（位于`kernel/system_call.s`），将在内核栈中压入的寄存器当作参数传递给`copy_process`（位于`kernel/fork.c`），这里可以看见`copy_process`原型的参数顺序刚好与系统调用进入内核时的压栈顺序相反。这些寄存器代表了父进程的状态，将用于`copy_process`创建子进程
![](attachment/9f2dfda5f53b12dff0c5b678c0230fe1.png)
![](attachment/545f6b671736fb44dfde1345b0c75cff.png)
### 2. 为子进程分配PCB
在`copy_processs`函数内部，首先调用了`get_free_page`函数为子进程分配了大小为一个页表（结合第一章，大小为4KB）的内存，进程的PCB将会放在这段内存里（后续会看到这段内存还作为了子进程的内核栈）。`get_free_page`函数会在内核的内存管理系统中找到一个尚未使用的物理页面，并返回一个指向该页面起始地址的指针（通过内存位图`mem_map`,回忆第一章，0代表空闲）。
```c
struct task_struct *p;
p = (struct task_struct*) get_free_page();  // allocate new memory page to child process
```
接着`copy_process`在新进程的PCB中设置各种状态（例如进程号、进程状态等），为新进程分配一个新的进程号(PID)，并初始化其各种状态，如进程状态、父进程ID、时间片计数器等。
![](attachment/a7dc7f4a3fb6f6a4c1c13204acce6c2e.png)
### 3. 为子进程创建内核栈
子进程的内核栈是通过设置子进程的 TSS 结构体中的 `esp0`和`ss0`字段来实现的
```c
 p->tss.esp0 = PAGE_SIZE + (long) p;
```
由于系统给PCB指针`p`分配了1页新内存,所以`PAGE_SIZE + (long) p` 让 `esp0`正好指向该页顶端  ( 还记得吗? 栈是由高地址到低地址堆起来的 ) 。
当然，我们还需要设置`ss0`，`p->tss.ss0 = 0x10` 语句的作用是设置子进程的内核栈所在的段选择子（Segment Selector）为内核数据段（Kernel Data Segment）的选择子，0x10 是内核数据段选择子的值。设置子进程的内核栈所在的段选择子为内核数据段的选择子，可以确保子进程的内核栈位于内核数据段中，从而使子进程可以访问内核中的数据
```c
p->tss.ss0 = 0x10
```
这样, `ss0:esp`就用作了子进程在内核态执行时的栈顶指针, 子进程拥有的页表的高地址开始的部分就用作了子进程的栈。
**旁注：esp与esp0**
> esp 和 esp0 都是x86架构下的寄存器。
> esp（Extended Stack Pointer）是x86架构下的栈指针寄存器，用于指向当前栈顶的位置。在进程执行期间，esp 寄存器通常用于指向进程的用户栈或内核栈的栈顶位置。
> **esp0 是x86架构下的TSS（Task State Segment）结构体中的一个字段，用于指示内核栈的栈顶位置**。当一个进程从用户态切换到内核态时，操作系统需要使用该进程的内核栈，以保存该进程在内核态执行期间使用的寄存器状态等信息。因此，内核需要知道该进程的内核栈的位置。在Linux 0.11版本中，进程的TSS结构体中的 esp0 字段存储了该进程的内核栈的起始位置，当该进程从用户态切换到内核态时，内核将使用 esp0 中存储的值来确定该进程的内核栈的栈顶位置。
> 需要注意的是，在Linux 0.11版本中，由于没有使用分段机制，TSS中的段基地址为0，因此 esp0 存储的是相对于物理内存起始位置的偏移量。在进程切换时，内核需要将 esp0 中的偏移量加上物理内存的起始地址，以计算出实际的内核栈顶指针位置。

### 4. 将父进程状态复制给子进程
`copy_process`将父进程的状态赋值给子进程。前面我们提到过，TSS是一个保持进程当前状态的数据结构，而进程的状态是由一堆寄存器体现的，因此在这一步中，`copy_process`将传入的寄存器参数全部用于初始化子进程的TSS，由此完成状态的复制。
![](attachment/5e39b3abb1bc5e7f4330d928004e1682.png)
![](attachment/97bcb18bfbfeb7e9317be7ad13681c7d.png)
注意这里，子进程`eip`、`esp`、`ss`等寄存器均是父进程的值，而这些值是在父进程进入内核时压入的值，因此这些值是父进程在用户状态下的值，由此可见，子进程和父进程共享用户栈，因为它们的`ss:esp`指向了同一个。并且无论是子进程还是父进程，返回用户状态时，都会返回到同一条语句的位置( `int 0x80`的下一条指令)，因为它们的`CS:IP`指向了同一个地址
![](attachment/9f2dfda5f53b12dff0c5b678c0230fe1.png)
**旁注：父子进程共享用户栈，只存在于早期linux中**
> CPU进程调度中，子进程独立于父进程吗？
> 在CPU进程调度中，子进程是独立于父进程的。当一个进程创建了一个子进程后，子进程会拥有自己的进程ID，并且会复制父进程的内存空间和代码段。这样，子进程就可以独立地运行，并且可以在其自己的地址空间中执行代码。子进程的运行不会影响父进程的运行，而且子进程可以与父进程并行执行。但是，子进程可以通过进程间通信（IPC）机制与父进程进行通信，以便共享信息和资源。
> 要是父进程结束了，父进程伴随的用户空间也释放了，那子进程怎么执行？子进程不是和父进程共享用户空间吗？
> 当父进程结束时，它的用户空间会被释放，但是子进程并不会受到影响。子进程在创建时会复制父进程的内存空间和代码段，这些内存空间和代码段被子进程独立地使用，因此子进程并不与父进程共享用户空间。这意味着，即使父进程已经结束，子进程仍然可以继续运行，并且可以在其自己的地址空间中执行代码。
> 需要注意的是，当父进程结束时，子进程的父进程ID会被设置为1，也就是init进程的ID。这是因为在Unix-like操作系统中，init进程是所有进程的祖先进程，当一个进程的父进程结束时，它的父进程ID会被设置为init进程的ID。
> 你这么说，那为什么在linux0.11中，子进程和父进程指向同样的用户栈
> 在早期的Linux内核版本（如0.11版本）中，子进程确实会与父进程共享用户空间，包括用户栈。这是因为在这个版本的内核中，子进程的创建是通过在父进程的地址空间中复制一个新的进程描述符来实现的。这个新的进程描述符包含了子进程的所有信息，包括代码段、数据段、堆栈和文件描述符等。因此，子进程和父进程共享同样的用户栈。
> 不过，在后来的版本中，Linux内核对进程创建和管理进行了改进，子进程的创建不再与父进程共享用户空间。现代的Linux内核中，子进程会创建自己的用户栈，这样就可以避免子进程和父进程之间的干扰和冲突。
> 那子进程怎么执行与父进程一样的用户代码？
> 在现代的Linux内核中，子进程创建时会复制父进程的代码段、数据段和堆栈等信息，但是子进程会创建自己的用户栈。这样，子进程就可以在自己的用户栈上执行与父进程相同的用户代码，而不会与父进程共享用户栈。子进程和父进程执行相同的代码，但是它们在不同的用户栈上执行，这样就可以避免子进程和父进程之间的干扰和冲突。
> 需要注意的是，子进程复制父进程的代码段、数据段和堆栈等信息是通过写时复制（Copy-on-Write，COW）技术来实现的。这意味着，当父进程或子进程需要修改这些信息时，内核会为它们分配新的内存空间，而不是在原来的内存空间中进行修改。这样可以避免父进程和子进程之间的内存冲突，提高系统的性能和稳定性。
> 子进程复制的代码段，是int 0x80之后的部分吗，我认为不包含是父进程调用fork函数之前的部分
> 您的理解是正确的。在现代的Linux内核中，子进程复制的代码段包含了父进程调用fork函数之后的所有代码，但是不包括调用fork函数之前的代码。这是因为在调用fork函数之前的代码是父进程的独有部分，而在调用fork函数之后的代码是父进程和子进程共享的部分。
> 具体来说，当父进程调用fork函数时，内核会为子进程创建一个新的进程描述符，并复制父进程的代码段、数据段和堆栈等信息。但是，由于fork函数是在父进程中调用的，因此子进程不会复制调用fork函数之前的代码。子进程从fork函数返回的位置开始执行，这个位置是在int 0x80指令之后的位置，也就是父进程调用fork函数之后的位置。
> 需要注意的是，子进程和父进程之间的区别是子进程会从fork函数返回0，而父进程会从fork函数返回子进程的进程ID。这样，父进程和子进程就可以通过返回值来区分彼此。

### 5. 进程的返回值
> 从父进程返回的是子进程的PID，从子进程返回的是0

`cope_process`到了尾声，它将创建的子进程的PID作为返回值，即将寄存器`%eax`设置为子进程的PID值，由此`sys_fork`返回子进程PID。
![](attachment/48b3a4564299e00c537ad89e4a1aa6e0.png)
如果在执行`sys_fork`函数时父进程**没有**遇到阻塞，即不会在执行完`sys_fork`之后调用`reschedule`函数，那么中断处理程序`system_call`函数就会返回子进程的PID，进而在用户态`fork`函数的`int 0x80`指令结束后`%eax`的值就是子进程PID，并作为返回值`res`返回给用户程序
![](attachment/545f6b671736fb44dfde1345b0c75cff.png)
![](attachment/77ee6da89546a4114df2d33fbf821a72.png)
子进程的`%eax`在创建时被设置为`0`，在父进程中，如果创建好了子进程，但如果后续遇到了阻塞，执行了`reschedule`函数，调度到了子进程，执行进程的切换，CPU开始执行子进程。那么从子进程返回时，是返回到父进程相同的用户程序位置。因此在用户程序可以对`fork`的返回值进行判断，如果为`0`则是从子进程返回，反之从父进程返回。
看一个示例：
```cpp
#include<unistd.h>
#include<stdio.h>

void main(int argc, char* argv[])
{
    if(!fork())
        printf("I am son!\n");
    else
        printf("I am father!\n");
}

```
![](attachment/77ee6da89546a4114df2d33fbf821a72.png)
这里的输出表明，父进程先被执行，`fork`函数返回子进程的PID，输出`"I am father !"`。后续再执行子进程，`fork`函数返回`0`，输出`"I am son !"`
什么情况下会先输出`"I am son !"`，再输出`"I am father!"`呢？
当父进程创建好了子进程之后遇到阻塞，或者时间片用完了，CPU就会执行调度程序`schedule`，调度到子进程，那么子进程就会先于父进程执行。不仅如此，在多核CPU上，子进程和父进程可能同时执行，如果子进程执行的更快，也会先执行输出
下面我们来验证一下：
在`fork`之后，父进程在打印`"I am father"`之前先调用`wait`函数等待子进程结束后再继续执行。那么如果子进程还没有结束或开始执行，`wait`函数会阻塞父进程，开始执行子进程，直到子进程结束并返回其退出状态。因此一定会先输出`"I am son !"`，再输出`"I am father!"`
```cpp
#include<unistd.h>
#include<stdio.h>
#include<sys/wait.h>
void main(int argc, char* argv[])
{
    if(!fork())
        printf("I am son!\n");
    else
    {
        wait(NULL);
        printf("I am father!\n");
    }
        
}

```
![](attachment/69e55d7cd42de97dab21bb828f85738e.png)
## 8) 详解schedule函数
```cpp
schedule(void)
{
	int i,next,c;
	struct task_struct ** p;  // 进程表

/* check alarm, wake up any interruptible tasks that have got a signal */

	for(p = &LAST_TASK ; p > &FIRST_TASK ; --p)  // 唤醒的收到信息的等待进程
		if (*p) {
			if ((*p)->alarm && (*p)->alarm < jiffies) {
					(*p)->signal |= (1<<(SIGALRM-1));
					(*p)->alarm = 0;
				}
			if (((*p)->signal & ~(_BLOCKABLE & (*p)->blocked)) &&
			(*p)->state==TASK_INTERRUPTIBLE)
				(*p)->state=TASK_RUNNING;
		}

/* this is the scheduler proper: */

	while (1) {
        // counter有两个含义
        // 1. 进程运行过程中动态变化的优先级值 (priority是初始优先级，在进程创建时分配)
        // 2. 进程的时间片
		c = -1; 
		next = 0;
		i = NR_TASKS; // 最大的进程数
		p = &task[NR_TASKS]; // 进程在进程表中的索引值 = PID - 1 ，这里是指向最后一个进程的后一个位置
		while (--i) {
			if (!*--p)  // 减法先执行，因此不会发生越界访问
				continue;
			if ((*p)->state == TASK_RUNNING && (*p)->counter > c) // 这个if语句，用于在所有就绪态的进程中
				c = (*p)->counter, next = i;  // 挑出counter值最大的那个，
                                              // 这里的counter可视为含义1-优先级，即挑出优先级最大的那个
		}
		if (c) break;  // 挑出了counter设置为next，跳出
        
        // 所有就绪态的进程的剩余可执行时间均为0，则挑不出可以执行的next，即表示所有就绪进程的时间片都用完了，
        // 那么就需要重置时间片。如何重置呢？
        // 根据进程的初始优先级priority,将所有进程重置时间片(包括阻塞态的进程)，priority越大，counter越大, 
        // 具体来说就是将当前counter值翻倍，再加上初始优先级priority
        // 由此可见，进程如果被多次执行这条语句，其优先级会越来越大。而阻塞的进程才会被多次执行该语句，
        // 因此在阻塞状态下越久的进程，优先级counter的值会越大，保证了这样的进程转为就绪态后能立即执行，避免了饥饿
        // 因此该函数是时间片轮转调度和优先级调度的结合，并只用了一个counter变量
		for(p = &LAST_TASK ; p > &FIRST_TASK ; --p)
			if (*p)
				(*p)->counter = ((*p)->counter >> 1) +
						(*p)->priority;
	}
	switch_to(next);  // next就是选择的进程在进程表中的索引
}
```
## 9) 信号量实现进程的走走停停
多进程的合理推进体现在进程能在正确的地方停下，并在符合条件的情况下继续执行，即正确的走走停停。多进程通过对信号量(semaphore)的检测(test)和设置(set)实现这一点。下面以经典的生产者-消费者为例讲述这个概念
消费者向BUFFER索取资源时，对信号量有以下逻辑
```c
P(semaphore s) // 消费资源
{
    --s.value;  // 索取一个资源
    if(s.value<0) sleep(s.queue); // 如果资源数为负数，则说明资源是欠缺状态，该进程进入睡眠(停)
}
```
生产者向缓冲区BUFFER写入时，对信号量有以下逻辑
```c
V(semaphore s) // 生产资源
{
    ++s.value; // 生产一个资源
    if(s.value<=0)  wakeup(s.queue); // 如果资源增1后为非正数，那之前资源必然欠缺，必然有进程在睡眠，因此唤醒(走)
}
```
可以看出，通过对信号量的test&&set能够实现进程的走走停停
![](attachment/022618c6c2df7c53f1385e093b46d9bf.png)
## 10) 临界区机制对信号量提供保护
进程对信号量执行修改时，可能会因为时间片结束而阻塞，CPU转去执行其它进程，而其它进程也可能修改同一信号量，这将造成信号量的语义错误，例如对资源信号量`s`的修改
![](attachment/5fd1fddb244160f8985c8162d69751f1.png)
这种错误，归根结底是不可预知的调度顺序造成的，因此我们引入临界区的概念：
临界区就是在同一时刻只能有一个进程进入的代码段，这个代码段的作用是修改信号量，因此每个进程都有这个代码段，但同一时刻只能有一个进程进入该代码段进行修改操作，避免了一个进程修改到中途，而另一个进程执行修改的情况
![](attachment/022618c6c2df7c53f1385e093b46d9bf.png)
对以上结构，有以下3个原则：
![](attachment/07b1a26be34a52d64824abce91c15e76.png)
## 11） 进入临界区的算法
### 1. 轮转法（turn）
通过一个变量，实现互斥关系
这个方法存在的问题在于，如果P0进入临界区并退出后，P1一直得不到调度，而P0也因为设置了turn =1 而无法进入临界区，不满足有空让进
![](attachment/7210c3d6fbde68b1e7705b12b56e6d38.png)
### 2. 标记法（flag）
为每个进程分配一个标记，在进入区通过检测其它进程的标签检测是否有其它进程想进入临界区，如果没有，则进入临界区
这个方法的问题在于，如果P0执行完`flag[0] = true`语句后阻塞，调度到P1，那么此时`flag[0]`，`flag[1]`都是true，将没有进程能进入临界区
![](attachment/022618c6c2df7c53f1385e093b46d9bf.png)
### 3. Peterson算法
![](attachment/d589f866c98c4ea05c31a837ae10ba82.png)
![](attachment/75eb7fac02ee199b822f199e5e69d09f.png)
### 4. 多个进程: 面包店算法
![](attachment/75eb7fac02ee199b822f199e5e69d09f.png)
![](attachment/07b1a26be34a52d64824abce91c15e76.png)
### 5. 硬件方法: 关中断，开中断
`cli()`置标志寄存器的IF位为0，CPU不响应可屏蔽中断（时钟中断属于可屏蔽中断），即关中断。`sli()`置标志寄存器的IF位为1，CPU响应可屏蔽中断。这样保证了在执行临界区代码时，进程不会因为时间片用完了而调度，间接实现了原子操作
但由于多核CPU有多个处理器，而进程执行`cli`和`sti`只能影响正在执行它的核，而不能保证其它处理器是不响应可屏蔽中断的状态，因此其它核可能执行会进入临界区的进程，引发信号量错误
![](attachment/0cf71efb20d9854b0a1e6e1cfb8a3252.png)
### 6. 原子指令法
![](attachment/7210c3d6fbde68b1e7705b12b56e6d38.png)
## 12) sleep_on中隐藏的队列
```c
void sleep_on(struct task_struct **p) {
    struct task_struct *tmp;

    if (!p)
        return;

    if (current == &(init_task.task))
        panic("task[0] trying to sleep");

    tmp = *p;
    *p = current;
    current->state = TASK_UNINTERRUPTIBLE;

    schedule();

    if (tmp)
        tmp->state = 0;
}
```
队列就隐藏在这两条语句中：`tmp = *p;` `*p=current` 
这条语句让`p`指向的指针(图中用空白方块表示) 指向 当前进程的PCB `current`，而让一个临时变量`tmp`指向原队列中的队首PCB，`tmp`存储在当前进程的内核栈中，因此在执行这个进程时，可以通过tmp找到等待队列的下一个进程，而在“下一个进程”的内核栈中也有一个临时变量`tmp`指向“下下个进程”，因此这个队列通过每个进程中的tmp链接起来了
![](attachment/a05e697174deb4b8d970e125f4076696.png)
当进程被重新唤醒后，进程从上次停下的地方即sleep_on函数中的`schedule`语句之后继续执行，因此执行的是
```c
if (tmp)
        tmp->state = 0;   //  唤醒下一个进程
```
如果存在这样一种调度顺序，即唤醒下一个进程后，CPU就调度到下一个进程，那么被唤醒的进程就将不断的唤醒等待队列中的下一个进程，直至唤醒所有进程，然后由schdule函数决定调度谁。这样做对等待同一信号量的多个进程来说，就不只是先来先执行了，而是优先级高的执行（结合P操作中的`while`语句(而不是常规的`if`语句)）
# 4. 内存管理
## 1) 进程载入内存: 运行时重定位
运行时重定位，也就是常说的动态重定位，下面以一个例子来讲述
假设进程中有一个函数调用指令`call 0x40`(假设该语句在段的起始位置)，该语句的目标地址是`0x40`（即相对于段的偏移量是`0x40`），当进程被载入内存的空闲区域后，`call 0x40`位于地址`0x1000`，那么实际上该该语句要跳转的目标在地址`0x1040`处，但是如果没有地址转换机制，CPU在`call 0x40`时只会跳转到`0x40`处，这将产生错误。因此我们需要有一种在执行语句时(即程序执行时)能够进行地址转换的机制。
运行时重定位就是这样一种机制，操作系统在进程载入内存时，记下它在内存中的起始地址（即基地址，在这个例子中是`0x1000`）放入进程的PCB中。当调度到这个进程时，OS将PCB中的基地址写入CPU的基地址寄存器（EBX），在执行进程的指令时，操作系统会将指令中的地址（称逻辑地址）加上基地址寄存器中保存的基地址得到物理地址，并将这个计算得到的物理地址作为目标地址。
这里对逻辑地址进行阐述：
> 进程的逻辑地址就是将其看作从 0 开始的一段程序。每个进程在其逻辑地址空间中都有自己的“私有”视图，包括代码、数据、堆和栈等不同的内存区域。进程在编写和执行时，通常会使用这些逻辑地址来访问内存。
> 逻辑地址的一个优点是它们允许程序员专注于程序本身的逻辑结构，而无需关心底层的物理内存布局。逻辑地址空间为进程提供了一个抽象层，使其看起来就像它是在一个独立的、从 0 开始的内存空间中运行。
> 操作系统负责将这些逻辑地址转换为虚拟地址（如果使用了段表的话），然后再将虚拟地址转换为物理地址。这种地址转换机制使得每个进程都可以在自己的地址空间中独立运行，同时确保它们不会相互干扰或访问其他进程的内存。

![](attachment/07b1a26be34a52d64824abce91c15e76.png)
## 2) 运行时重定位助力进程的交换
当进程阻塞时，操作系统可能会选择将其从内存中换出（swap out），以释放内存资源供其他进程使用。当进程重新成为就绪态并被CPU调度到时，进程需要重新载入内存，那么此时进程所在的内存可能就不是之前的那个内存地址，根据运行时重定位机制，此时进程PCB中关于进程基地址的信息被更新，因此进程换出换入后仍然可以继续正确的执行，而不会发生错误的内存访问。
编译时重定位（静态重定位）之所以被淘汰，就是因为它不支持进程换入换出过程中进程地址的变化，进程只能放入内存的固定位置，该机制在程序被编译时根据进程即将载入的位置而修改程序的源码，例如进程将载入内存地址`0x1000`处（所以该机制还要预留内存，确保这个内存空闲），那么编译器在编译它时，将修改`call 0x40`为`call 0x1040`。
## 3) 进程分段
进程之所以要分段（编译器的任务），是因为不同的程序需要访问的数据和代码具有不同的特点和访问权限，需要分别存储在不同的内存区域中，以便操作系统进行管理和保护。
常见的进程内存分段包括代码段、数据段、堆栈段等。
> 代码段（Code Segment）用于存储程序的可执行代码，包括函数、指令和常量等。代码段通常具有只读权限，即程序在执行过程中无法修改代码段中的内容。这种只读权限可以保证程序执行的安全性，防止程序意外修改自身的代码。
> 数据段（Data Segment）用于存储程序中已经初始化的全局变量、静态变量和常量等。数据段通常具有读写权限，允许程序在执行过程中修改数据段中的数据。由于数据段中的数据通常是程序的重要状态，因此需要进行合理的管理和保护。
> 堆栈段（Heap and Stack Segment）用于存储程序执行时动态分配的内存和函数调用时的局部变量、参数、返回值等。堆和栈通常是分开的，其中堆用于存储动态分配的内存，而栈用于存储函数调用时的临时数据。堆和栈的大小是动态变化的，因此需要进行动态的内存管理和保护。

通过将进程内存分为不同的段，操作系统可以针对不同的段进行不同的内存管理和保护，从而提高程序的安全性和稳定性。
同时，进程内存分段还有助于提高内存的利用率，从而提高系统的性能和效率。进程内存分段可以提高内存利用率的原因主要有以下两点：
> 1. 内存分段可以针对不同类型的数据和代码进行优化存储。例如，代码段通常具有只读权限，因此可以共享一份代码段数据，以便节约内存空间。另外，堆和栈的大小是动态变化的，因此需要进行动态的内存管理和分配，从而提高内存利用率。
> 2. 内存分段可以提高内存的可重用性和共享性。不同进程中的相同类型的数据和代码可以共享一份内存空间，从而避免重复分配内存空间，提高内存利用率。例如，操作系统可以将多个进程中相同的动态链接库代码段共享一份内存空间，从而节约内存空间。

![](attachment/a05e697174deb4b8d970e125f4076696.png)
## 4) 进一步认识LDT与GDT
内存中进程的各段是分离的，而CPU访问指令/数据的方式是<段号，段内偏移>，因此要访问进程中的指令/数据，CPU就需要知道进程各段的起始地址，这个信息就保存在进程的段表中，即LDT (Local Descriptor Table) 。进程在执行指令和访问数据时，先查询LDT获取基地址，进而得到目标地址，再执行操作。
这里再详细阐述一下CPU保护模式下用于寻址的段选择子(以CS为例)
> CS是在x86架构中的一个寄存器，用于存储CPU当前正在执行的代码段的段选择子。段选择子是一个16位的值，包含了两部分信息：段描述符表中该段描述符的索引值（Index，可以理解为段号），以及一个RPL（Request Privilege Level）字段，用于限制当前进程的访问权限。在执行指令时，CPU会使用CS中存储的段选择子来访问GDT（Global Descriptor Table）或LDT（Local Descriptor Table）中的段描述符，并从中获取当前代码段的基地址和限长等信息，从而计算出代码段中指令的实际物理地址。
> 每当CPU加载一个新的段选择子时，它会将对应的段描述符缓存到GDTR指定的内存区域中。这个缓存区域称为段描述符缓存（Descriptor Cache）。这样，在下一次访问同一个段时，CPU就可以直接从段描述符缓存中获取对应的段描述符，而不需要再次访问GDT。这种缓存机制可以提高内存访问效率，并减少对GDT的访问次数。
> ![](attachment/7210c3d6fbde68b1e7705b12b56e6d38.png)
> 段描述符（64bits）是在GDT或LDT中的一个数据结构，用于描述一个内存段的基地址、限长、访问权限等信息。在程序执行过程中，操作系统通过段描述符来管理和保护内存段，从而保证程序的安全性和稳定性。段选择子则是用于访问GDT或LDT中的段描述符的索引值，它的值决定了CPU将访问哪个段描述符。
> ![](attachment/a05e697174deb4b8d970e125f4076696.png)
> 需要注意的是，在x86架构中，一个进程可以使用多个代码段和数据段，每个段都由一个段描述符描述。因此，程序执行过程中需要使用多个段选择子来访问不同的段描述符。除了CS寄存器之外，还有DS（Data Segment）、SS（Stack Segment）、ES（Extra Segment）等寄存器，用于存储访问不同段的段选择子。

LDT是正确执行和访问进程的关键，因此每个进程都维护一个自己的LDT，在进程切换时，LDT表也要随之切换（见lab4）。
![](attachment/a85afbd69b690948359583ead1d13729.png)
现在对1)中提到的“进程载入内存时将基地址放入PCB中”进行更正：
> 在将进程载入内存时，操作系统会初始化该进程的LDT表（也是一个段）并写入该进程的内存空间中，操作系统会将LDT表的段选择子写入该进程的TSS（Task State Segment）中的LDT表寄存器字段中。（将LDT与PCB关联）
> 当该进程被调度执行时，CPU会从该进程的TSS中获取LDTR（LDT Register）中的值，并将其加载到CPU的LDTR中，以便该进程能够正确地访问自己的局部内存段。因此，LDTR的值会从该进程的PCB中获取，并在进程载入内存时被设置。
> LDT表的存储位置由LDTR中的地址决定。LDTR是一个48位的寄存器，它由一个16位的段选择子和一个32位的线性地址组成。当CPU需要访问LDT表时，它会从LDT表寄存器中读取段选择子，从而确定要访问的LDT表在GDT（Global Descriptor Table）中的位置。然后，**CPU会使用段选择子从GDT中读取LDT表的段描述符，并从中获取LDT表在内存中的起始地址**。
> ![](attachment/f79658fdbb805322f1a6a578ef030add.png)

区别GDT与LDT：
> 在x86架构中，GDT（Global Descriptor Table）是一个全局的段描述符表，用于存储系统中所有进程和内核所使用的段描述符。而LDT（Local Descriptor Table）表则是每个进程都有自己的局部段描述符表，用于存储进程的局部段描述符。
> 因此，GDT和LDT是两个不同的概念，不应混淆。GDT是系统级的全局段描述符表，用于存储所有进程和内核所使用的段描述符，而LDT是进程级的局部段描述符表，用于存储进程的局部段描述符。
> 具体来说，在x86架构中，每个进程都有自己的LDT表，用于存储进程的局部段描述符。LDT表通常存储在进程的内存空间中，与其他数据和代码一起存储在进程的用户地址空间中。而GDT则是一个全局的段描述符表，用于存储系统中所有进程和内核所使用的段描述符。GDT表通常存储在系统的内存空间中，并由操作系统维护和管理。
> 因此，GDT和LDT是两个不同的概念，GDT是系统级的全局段描述符表，而LDT是进程级的局部段描述符表，它们在作用和范围上是不同的，不能混淆。


## 5) 内存分区-有关进程所需内存
进程的段要载入内存，那么OS就要给进程分配空闲的内存，我们称内存中离散的空闲内存为空闲分区。对整个内存，OS可建立空闲分区表和已分配分区表来管理内存
![](attachment/a85afbd69b690948359583ead1d13729.png)
对进程的段内存请求，OS有多种算法来决定分配从哪个空闲分区分配内存给它，比如首先适配(简单，执行速度快)，最佳适配(会产生内存碎片，空闲分区越来越小)，最差适配(将导致没有特别大的分区)
![](attachment/a85afbd69b690948359583ead1d13729.png)
这种可变空闲分区机制将导致大量的内存碎片问题，即内存明明还有足够的空闲，但是都是一堆碎片分区，以至于任何一个分区都不足以装下进程的一个段，这造成了内存的浪费。一个自然而然的想法是重新调整内存，将碎片分区整合在一起，但在执行这个内存操作时，进程显然是不能继续执行的，因为它的地址在变化中，这将导致CPU的低效，用户的体验感也不好。因此才有了内存分页的机制
![](attachment/00b606854598c5ba4b5d5647c190adcf.png)
## 6) 内存分页-有关物理内存
将内存划分为一个一个大小固定的单位，称之为页（回忆OS的启动部分的`mem_init`函数，操作系统在启动时就通过`mem_map`将内存分成一页一页的，通常是4K），内存分页使用离散的、大小固定的页面来为进程分配内存，这将彻底消除内存碎片问题，因为它不存在内存分区那样因为太小而不能分配给进程的问题，因为页的分配可以是离散的（进程的同一个段在内存中可能不连续）。唯一可能产生的内存浪费就是当进程请求的内存空间大小不是页面大小的整数倍，那么最后一页可能会有一些未使用的空间，但这个未使用的空间仅仅只是一个页面内的空闲空间（所以是很小的内存浪费），而不会导致内存碎片的产生（因为已经分配出去了，只是进程没有使用）。
![](attachment/26795f5d2a90e3b1abc6b1fdc9d39408.png)
在内存分页机制下，进程的同一个段（Segment）可能会被分成多个页面（Page）并散布在内存中的不同位置，这意味着进程的同一个段在内存中可能不连续。这种情况发生的原因是，内存分页的单位是页面而不是段，进程的段可能跨越多个页面。我们要引入新的数据结构来实现进程逻辑地址到物理地址的转换。我们要为进程的各段维护一个**页表**(Page Table)，将段的逻辑页号/虚拟页号映射到物理页框号，下面以一个逻辑地址->物理地址的计算例子展现页表的作用
对逻辑地址`0x2240`（对虚拟地址也是同样的，因为进程的虚拟地址也是一个从0开始的一段内存），我们(MMU)先计算它在段的第几个页号上：
$\frac{0x2240}{4K} = 0x2240\gg12 = 0x2$
因此该地址在段的第2个页面上，通过查询段的页表，可知段的第2个页面对应的物理页框号为3，所以该逻辑地址对应的实际物理地址为
$3*4K + 0x240=3\ll12 +0x240 = 0x3240$
![](attachment/f79658fdbb805322f1a6a578ef030add.png)
## 7) 多级页表-书本的章和节的思想
假设一个进程的虚拟地址空间为 4GB（$2^{32}$字节），物理地址空间为 1GB（$2^{30}$ 字节），页面大小为 4KB（$2^{12}$字节），那么它的页表项数量将达到 $2^{32} / 2^{12} = 2^{20}$ 个，需要占用大约 4MB 的内存空间。如果直接使用单级页表来管理进程的地址空间，需要在内存中维护一个包含$2^{20}$个页表项的页表。由于页表项数量巨大，而且大部分页表项并不会被频繁使用，这样会导致内存空间的浪费和访问效率的降低。为了解决这个问题，操作系统通常采用多级页表来管理进程的地址空间。多级页表将页表划分为多个级别，每个级别的页表包含一部分页表项。例如，两级页表结构中，第一级页表包含多个页目录项，每个页目录项指向一个第二级页表，第二级页表包含多个页表项。当进程访问某个虚拟地址时，操作系统会首先查询第一级页表，找到对应的页目录项，然后再查询第二级页表，找到对应的页表项，从而确定该虚拟地址对应的物理地址。
下面是一个简单的多级页表实例：
假设一个进程的虚拟地址空间为 4GB（$2^{32}$字节），物理地址空间为 1GB（$2^{30}$ 字节），页面大小为 4KB（$2^{12}$字节），采用两级页表结构。第一级页表包含 1024 个页目录项，每个页目录项大小为 4 字节，第二级页表包含 1024 个页表项，每个页表项大小也为 4 字节。这样，每个页表项对应一个 4KB 的物理页框，每个页目录项指向一个 4MB（$1024\times4KB = 4MB$） 的虚拟地址空间。
当进程访问一个虚拟地址 0x12345678 (在这之前，根据段表，将指令中的地址转换为虚拟地址) 时，需要将该虚拟地址转换为对应的物理地址。首先，操作系统根据虚拟地址的高 10 位（0x12345，即除以$2^{22}$或地址右移22位 以确定在哪个页目录项）查询第一级页表，找到对应的页目录项。假设该页目录项对应的第二级页表的物理地址为 0x12340000。然后，操作系统根据虚拟地址的中间 10 位（0x6）查询第二级页表，找到对应的页表项。假设该页表项对应的物理页框的物理地址为 0x56780000。最终，操作系统将虚拟地址 0x12345678 映射到物理地址 0x56785678，这个物理地址是进程所使用的实际物理地址，可以用于实际的内存访问操作。
在上面的例子中，使用两级页表可以将每个页表的大小降低到 8KB（一级4KB+二级4KB*1），而不是使用单级页表时需要的 4MB。这样可以降低页表的访问开销和内存空间的浪费，提高系统的内存利用率和性能。多级页表的级数可以根据需要进行调整，以适应不同的内存管理需求和硬件环境。
页目录表和二级页表都在内存中，页目录项并不是始终被填满的。在使用分页机制的情况下，页目录项和页表项只会在需要时才会被填充。当进程访问一个新的虚拟地址时，如果对应的页目录项或页表项不存在，则操作系统会通过**缺页异常**等方式将其填充到内存中。因此，**只有进程实际使用的虚拟地址才会被映射到物理地址，而未使用的虚拟地址则不会被映射到物理地址，也就不会占用额外的内存空间**。这种按需分配的方式可以有效地节省内存空间，提高系统的内存利用率。因此实际上所有页表(一级页表+二级页表)在内存占的内空间为**一级页表4KB+二级页表4KB*有效页目录项个数**，比如下图，使用了两个页目录项，因此页表总内存为
$4KB+4KB\times3=16KB$
![](attachment/3e62cb394c3e34f04693136b17ab094f.png)
![](attachment/a85afbd69b690948359583ead1d13729.png)
## 8) TLB：一种缓存
可以将TLB（Translation Lookaside Buffer）视为一种缓存，但它不是用于缓存数据的Cache，而是用于缓存虚拟地址到物理地址的转换结果，这样CPU就可以避免多次访问内存中的多级页表，从而提高访问速度。
![](attachment/50bc769c1e6db59af741f48d8624ac96.png)
## 9) 虚拟内存：段页结合
这里引入了虚拟地址空间的概念
> 进程的虚拟地址空间是指进程可以使用的虚拟地址的范围。在使用分页机制的情况下，进程的虚拟地址空间通常被划分为多个页，每个页的大小为固定的值，例如4KB或2MB。进程的虚拟地址空间通常包括代码段、数据段、堆、栈等不同的区域，每个区域都有自己的起始地址和大小。操作系统会通过段表或页表将进程的逻辑地址映射到实际的物理地址，从而让进程可以访问到内存中的数据和指令。
> 操作系统负责管理页表，它为每个进程维护一个独立的页表。当进程被创建时，操作系统会为它分配一块虚拟地址空间，并为这个进程创建一个页表。操作系统还会将页表中的一些页表项设置为无效，这些页表项对应的虚拟页面还没有被分配物理内存。当进程访问这些无效的虚拟页面时，操作系统会触发一个缺页异常，然后根据需要为这个虚拟页面分配物理内存并更新页表。这个过程被称为页面调度。
> 进程的虚拟地址空间可以保证每个进程都有自己独立的地址空间，互不干扰，同时也可以避免不同进程之间的内存冲突和竞争。

进程有独立的虚拟地址空间（包括虚拟页号），在执行访存指令时，有以下的地址转换: 
逻辑地址(指令中的地址) $\xrightarrow{段表}$虚拟地址$\xrightarrow{页表}$物理地址
![](attachment/7c0c3e8a239918e820904293bd7101c2.png)
![](attachment/f79658fdbb805322f1a6a578ef030add.png)
## 10) copy_mem函数创建子进程页表
`copy_mem`用于在创建子进程的过程中被`copy_process`调用，该函数做了以下3件事

1. 为子进程分配虚拟内存，创建子进程的段表（LDT），可以看出linux0.11毕竟是早期的版本，不能保证进程的虚拟地址从0开始，而是根据进程号划分

![](attachment/7c0c3e8a239918e820904293bd7101c2.png)

2. 复制父进程的页目录表和二级页表

子进程和父进程共用物理内存页，但是各自要有独立的页表，因此子进程复制父进程的页表作为自己的页表
这里调用了`copy_page_tables`函数，该函数以父进程段基址和子进程段基址为参数，在Linux 0.11中，通过将段基址右移 22 位，可以得到页目录表的索引。接着，将这个索引乘以页表项大小（4字节）再加上页目录表的线性基地址（0xffc00000），就可以计算出页目录项的线性地址。然后，根据这个线性地址，我们可以找到对应的页表基址。
这里补充一下页目录表基址与CR3寄存器
> 操作系统为每个进程设置了一个独立的页目录表，以管理进程的虚拟内存。每个进程的页目录表在物理内存中具有不同的位置，但为了简化内存管理和地址转换，操作系统将当前运行进程的页目录表映射到线性地址（虚拟地址） 0xffc00000。这样做的目的是在处理当前进程的虚拟地址时，可以方便地访问其页目录表。
> 为实现这一目标，操作系统在切换进程时会执行以下操作：
> 1. 操作系统将新进程的页目录表物理基地址加载到 CR3 寄存器中。CR3 寄存器用于告诉内存管理单元（MMU）当前活动的页目录表的物理基地址。
> 2. 操作系统将当前运行进程的页目录表映射到线性地址（虚拟地址） 0xffc00000。这意味着操作系统会在页目录表中设置一个特殊的页目录项，将页目录表在虚拟内存中的基址设置为0xffc00000。这样，无论当前运行的是哪个进程，操作系统都可以通过这个固定的线性地址访问其页目录表，实际的物理基地址保存在CR3寄存器中。
> 
通过这种方式，操作系统能够在逻辑层面统一访问当前运行进程的页目录表，简化了地址转换和内存管理过程。

在函数中遍历父进程的页目录项，同时为子进程的页目录项申请一页内存来保存对应的二级页表。并在这个新申请的二级页表中，原封不动的拷贝父进程对应的那个二级页表
![](attachment/313f021e7970f73347285023bba01bc6.png)
![](attachment/41342817f9984b2f94c18bdf98dcf39b.png)
![](attachment/3336ab49b12ce0804a6b44d522450081.png)
![](attachment/db29d6bd5960e875b3baee55aa391979.png)
通过`copy_mem`函数，子进程就拥有了自己的页表，并且指向和父进程同样的物理内存页(被标记为已读)，此时还未实现父子进程的内存分离
![](attachment/3433e861e5085ced9ca3c7be18ad26e6.png)
当子进程想往内存中某个地址写入数据时，因为原内存页被设置为只读，而且要保证子进程和父进程的内存分离，因此OS为子进程想要写入的地址分配新的物理内存页，并修改子进程的页表，这就是写时复制
> 写时复制：当父进程或子进程需要修改信息时，内核会为它们分配新的内存空间，而不是在原来的内存空间中进行修改
> 在使用写时复制（Copy-on-Write，简称 COW）机制时，父子进程在一开始并不会为自己分配独立的内存空间，而是共享相同的物理内存页面。此时，这些共享的物理内存页面会被设置为只读。当父进程或子进程试图修改这些共享页面时，会触发一个缺页异常。
> 当操作系统捕获到这个缺页异常时，它会检查异常原因。如果是因为试图写入只读页面，操作系统会采取以下操作：
> 1. 为引发异常的进程分配一个新的物理内存页面。
> 2. 将原来共享的只读页面的内容复制到新分配的物理内存页面中。
> 3. 更新引发异常的进程的页表，将对应的虚拟地址映射到新分配的物理内存页面。
> 4. 将新分配的物理内存页面设置为可写。
> 
这样，引发异常的进程现在有了一个可写的内存页面，包含原先共享页面的内容。而原来的只读共享页面仍然保留在内存中，供其他进程（例如父进程或其他共享该页面的子进程）使用。当没有进程再使用这个只读页面时，操作系统会将其回收并释放相应的物理内存空间。

![](attachment/43730badbe2bf10c4a157a6d9194936f.png)
## 11) 内存换入

1. 存在的原因

因为进程的虚拟内存大于实际的物理内存，因此将进程只当前使用到的数据/代码页从磁盘换入内存，该机制支撑着虚拟内存机制。
> 内存换入（paging in）是操作系统的内存管理策略，通过将磁盘上的数据或代码页换入物理内存，使得进程能够访问所需的资源。这种策略的主要优点是提高了内存利用效率，允许多个进程共享有限的物理内存资源。
> 由于进程的虚拟内存通常大于实际的物理内存，操作系统需要在磁盘上存储这些虚拟内存页面。当进程需要访问某个虚拟内存页面时，操作系统会检查该页面是否已经在物理内存中。如果页面不在物理内存中，操作系统会将其从磁盘换入物理内存。

因此进程的虚拟页一开始并没有映射到物理页，只有在请求了该虚拟页后，OS才会将它换入内存物理页并将它与虚拟页映射，这种技术可以提高系统的可用内存
![](attachment/bbea916ea56dfc9a947de21da0b02567.png)

2. 缺页中断

当进程尝试访问一个不在物理内存中的虚拟地址时，会触发缺页中断。缺页中断是一种硬件中断，用于通知操作系统进程试图访问一个不在物理内存中的虚拟页面。
操作系统接收到缺页中断时，它会执行以下操作：

1. 确定引发缺页中断的虚拟地址（放入`cr2`寄存器）和相应的虚拟页面。
2. 检查该虚拟页面是否已经在磁盘上存储（例如，存储在交换分区或文件映射中）。如果是，则进行内存换入操作，将虚拟页面从磁盘加载到物理内存中。
3. 更新进程的页表，将虚拟地址映射到新加载的物理内存页面。
4. 恢复进程的执行，使其能够访问所需的虚拟页面

请注意，这里的内存换入操作可能会导致其他物理内存页面被换出（如果没有空闲页），以便为新换入的页面腾出空间。操作系统会根据内存管理策略（如 LRU 算法）选择一个合适的页面进行换出。
![](attachment/3433e861e5085ced9ca3c7be18ad26e6.png)

3. 缺页中断的代码实现

缺页中断处理程序`_page_fault`的主体是调用的`_do_no_page`函数，它完成3三件事

1. 确定虚拟页号
2. 申请物理内存页，将虚拟页放入物理内存页
3. 修改页表（建立映射）

![](attachment/26795f5d2a90e3b1abc6b1fdc9d39408.png)
![](attachment/26795f5d2a90e3b1abc6b1fdc9d39408.png)
## 12) 内存换出
在前一节内存换入已经提到，当物理内存已满时，内存换入之前应该先进行内存换出，将一页淘汰以腾出空闲页，那么选择哪一页淘汰就是内存换出的核心问题，这里主要讲3个算法，用缺页次数评价算法优劣

1. FIFO

这个算法的主要问题在于，可能刚刚换出的内存页，下一次就要换入，增加了磁盘读写次数，耗时高
![](attachment/bbea916ea56dfc9a947de21da0b02567.png)

2. LRU

LRU算法的全称是“Least Recently Used”，即最近最少使用算法。LRU算法利用了**局部性原理**，将最近最少使用的页面置换出去，以便为新的页面腾出空间。这样可以提高页面命中率，减少缺页中断，从而提高系统的性能。
![](attachment/26795f5d2a90e3b1abc6b1fdc9d39408.png)

3. clock

Clock算法是一种用于操作系统页面置换的**近似最近最少使用（LRU）算法**。由于实际实现真正的LRU算法需要较高的计算和维护成本(修改页面时要将它设置为正确的时间戳)，Clock算法被设计为一种相对简单且高效的替代方案。Clock算法的主要思想是模拟一个循环队列（类似时钟指针），在其中记录物理内存页面的访问情况
相比于LRU要维护一个复杂的数据结构，Clock算法为在每个页面条目中添加一个访问位，机制如下图
![](attachment/be45e9be004d61829c5b03272132030c.png)
具体来说，如果相对于一个R=0的页面（该页面在上一次时钟相遇时R从1置为0），时钟走完一圈回到该页面时，该页面访问位还是0，则说明该页面一圈的时间内(最近的时间)未被访问过，因此选择该页换出。
到现在，Clock还只有一个指针，那么引出第二个指针的目的，就在于定时的将页面的访问位置0，该指针遍历速度要更快，原因在于当缺页很少时，页面均是R=1,因此按照我们之前的说法，clock算法是将一圈R=1的页面置为0，然后换出为起点的页面，该算法退化为了FIFO算法，而且还有另外一种可能，页面被置0后被访问，可能导致页面永远不会被换出
> 在Clock算法中，定期清除访问位（R位）是为了防止一些页面的访问位一直保持为1，导致它们永远不会被置换。如果不定期清除访问位，那么一些频繁访问的页面的访问位会始终保持为1，这将导致它们在页面置换过程中永远不会被选中。
> 通过定期清除访问位，Clock算法可以确保每个页面都有被置换的可能性。当访问位被清除时，页面的“优先级”被重置，这样算法在下一次页面置换时将重新考虑所有页面。这有助于Clock算法更好地平衡内存资源，使得所有页面都有被换出的机会。
> 定期清除访问位的策略可以根据系统的需求和实际情况进行调整。在一些情况下，可能会选择在每次页面置换时清除一定数量的访问位；在其他情况下，可能会设置一个定时器，在固定时间间隔后清除所有访问位。具体的策略取决于系统的性能需求和资源限制。

![](attachment/00b606854598c5ba4b5d5647c190adcf.png)
OS中的颠簸现象：
> 颠簸（Thrashing）现象是指在操作系统中，当内存资源过度分配给多个进程时，导致大量的缺页中断和频繁的页面置换，使得系统的整体性能急剧下降。颠簸现象通常发生在系统的物理内存资源不足以满足所有运行进程的需求时。
> 当颠簸发生时，进程之间会竞争有限的内存资源，从而导致频繁的缺页中断。由于大量时间花费在处理缺页中断、页面换入和换出等内存管理任务上，进程实际的计算工作几乎无法进行。这导致系统运行缓慢，用户体验极差

![](attachment/26795f5d2a90e3b1abc6b1fdc9d39408.png)
![](attachment/55386b9183e912238f4ef08482495438.png)
# 5. 设备驱动与文件系统
## CPU如何使用外设
我们由简至繁，先看看CPU本质上是如何使用外设的。
CPU使用外设，本质上是对外设的端口 (端口的本质是寄存器) 进行写命令（out xx, al）完成的。
> 更详细的说，CPU通过与外设的端口进行通信来使用外设。在硬件层面，这些端口通常与设备的寄存器相关联，这些寄存器包含用于配置设备和控制设备行为的数据。通过对这些寄存器进行读写，CPU可以实现对外设的控制。通常，操作系统会使用设备驱动程序（Device Drivers）来与外设进行通信。设备驱动程序是一种特殊的软件，可以将CPU发出的指令转换成与特定硬件设备兼容的命令。操作系统通过调用设备驱动程序提供的接口，从而实现对外设的控制。

而设备受到CPU的指令后开始工作，在工作完成后向CPU发出中断信号，CPU就转去执行中断处理程序。
以上描述中CPU要干的就两件事，一个是向设备写，一个是中断处理。那么在设备驱动的相关代码中有关写指令和中断处理以外的其他指令，旨在提供给上层用户一个统一的接口 ，避免因设备的不同或设备厂商不同，而导致写操作成为一个复杂的事情。以向显示器输出为例，无论显示器是什么牌子的，通过这个统一的接口，用户都可以用printf打印语句。
![](attachment/26795f5d2a90e3b1abc6b1fdc9d39408.png)
这里提到的统一的接口，就是操作系统两大视图中的**文件视图**，用户使用外设，只需要处理设备对应的设备文件即可。设备文件是一种特殊类型的文件，它允许应用程序和操作系统以文件的形式与硬件设备进行交互。这种抽象简化了应用程序对外设的访问，因为它们可以像操作普通文件一样操作设备文件。但底层实现仍然依赖于设备驱动程序，以及通过端口（寄存器）与外设进行通信。
**旁注: **
> 设备驱动程序与设备文件
> /dev目录下的设备文件并不包含设备驱动程序本身。设备文件是Linux和类Unix操作系统中设备驱动程序与用户程序之间的接口。它们充当了一种抽象层，允许用户程序通过标准的文件I/O操作（如打开、读取、写入和关闭文件）与底层硬件设备进行交互。
> 设备文件通常分为字符设备文件和块设备文件。这两类设备文件在/dev目录下，以设备文件的形式表示。每个设备文件都有一个设备号（包括主设备号和次设备号），用于唯一标识该设备。操作系统使用设备号在内部映射到相应的设备驱动程序。
> 设备驱动程序本身是内核的一部分，负责管理硬件设备，并为用户程序提供了一组操作函数。当用户程序对设备文件执行I/O操作时，操作系统会根据设备号找到相应的设备驱动程序，然后调用设备驱动程序提供的操作函数来处理用户程序的请求。这样，设备驱动程序实际上是在内核空间执行的，而设备文件则位于用户空间。

![](attachment/be45e9be004d61829c5b03272132030c.png)
![](attachment/00b606854598c5ba4b5d5647c190adcf.png)
## 向显示器输出
printf函数内部将可变参数转换为字符数组格式，并将其存储在`buffer`数组中。然后，用系统调用sys_write将该字符数组写入标准输出流中，这在第二章讲述系统调用时说过，在这一章我们从`sys_write`接着向下探索以解开设备驱动程序的面纱
![](attachment/be45e9be004d61829c5b03272132030c.png)
### 从文件描述符fd到目标inode
我们先了解**操作系统怎么通过文件描述符fd找到目标inode**，再谈sys_open如何建立这个映射关系的，就知道sys_write是如何通过fd获取目标inode的了
源码中出现的filp数组是进程PCB中的文件指针数组，它包含指向全局文件表（file_table）中相应文件表项的指针，将进程的文件描述符（整数值）映射到全局文件表中的文件表项
全局文件表（file_table）则是系统级别的，**文件表中的每个条目指向一个 inode**，因此它将文件描述符映射到系统中的 inode。
所以通过文件描述符fd当做filp数组的索引`current->filp[fd]`得到对应的文件表项指针，再通过文件表的映射，就能够找到目标文件的inode `struct m_inode *inode_ptr = file_ptr->f_inode`。inode是一个结构体，存储了目标文件的相关信息，比如文件大小/类型/创建日期等，因为外设被OS抽象为设备文件，因此inode还存储了设备的信息，OS通过inode提供的信息确定了要写入的目标设备的信息（设备号），进而选择接下来的分支
而sys_open是如何建立这个映射关系的呢
> 1. 解析文件路径：sys_open 首先根据提供的文件路径名找到对应的 inode。这个过程涉及到遍历目录结构和搜索目录项，最终找到目标文件的 inode。(open_namei函数)
> 2. 在全局文件表中分配一个文件表项：接着，sys_open 在全局文件表（file_table）中分配一个空闲的文件表项，并将找到的 inode 指针存储在该文件表项的 f_inode 字段中。此外，还会设置文件访问模式（读、写或读写）和文件操作指针等信息。
> 3. 在进程的文件指针数组中分配一个文件描述符：然后，在当前进程的文件指针数组（filp）中分配一个文件描述符（fd），并将其指向全局文件表中的相应文件表项。通常，文件描述符会分配为当前进程中最小可用的整数。例如 0、1、2 等。在 Linux 系统中，0、1、2 分别对应了标准输入（stdin）、标准输出（stdout）和标准错误（stderr）
> 4. 返回文件描述符给进程
> 
至此， sys_open 系统调用建立了从文件描述符（fd）到进程的文件指针数组（filp）、全局文件表（file_table）和 inode 的映射关系之后，进程可以使用文件描述符执行后续的文件操作。
> 当进程需要进行文件操作时，例如读取、写入或关闭文件，它会使用已分配的文件描述符（fd）作为参数调用相应的系统调用，如 sys_read、sys_write 或 sys_close。
> 这些系统调用会根据文件描述符（fd）查找进程的文件指针数组（filp），以获取指向全局文件表（file_table）中相应文件表项的指针。接着，它们会访问文件表项中的 inode 指针，找到与文件关联的 inode。有了 inode，操作系统可以根据文件元数据和数据块指针来执行具体的文件操作。
> 这种从文件描述符到 inode 的映射关系使得进程可以方便地访问和操作文件，同时操作系统可以有效地管理文件资源和追踪文件状态。

![](attachment/be45e9be004d61829c5b03272132030c.png)
看下图源码，sys_write通过用文件描述符索引filp数组( `current->filp[fd]`)得到文件表条目，再通过文件表条目得到inode (`file->f_inode`)
![](attachment/9a986e22ba33aa2f07fb537819658b5d.png)
通过溯源操作系统的初始化过程，可以知道文件描述符0(标准输入stdin),1(标准输出stdout),2(标准错误stderr)均指向设备驱动文件`dev/tty0`
![](attachment/9a986e22ba33aa2f07fb537819658b5d.png)
### rw_char函数与crw_char数组
`sys_write`函数根据inode，判断目标设备是不是字符设备 (根据设备类型进行分支)，如果是，则向`rw_char`函数传入设备的设备号(也是inode中的信息)，该函数以设备号为索引通过`crw_char`数组找到并调用相应的设备驱动程序rw_ttyx（这里开始真正执行内核中的设备驱动程序！ rw: read or write）

1. crw_char数组：crw_char数组（在fs/char_dev.c文件中定义）是字符**设备驱动程序的注册表**。数组中的每个元素都指向一个字符设备驱动程序的操作函数表。crw_char数组使用设备号作为索引，将设备号映射到相应的设备驱动程序。在printf向显示器输出的过程中，/dev/tty0的设备号为4，对应于TTY设备驱动程序。
2. rw_char函数：rw_char函数（在fs/char_dev.c文件中定义）是一个通用的读/写函数，用于处理字符设备的读写操作。rw_char函数根据传入的设备号查找crw_char数组，然后调用相应设备驱动程序的读或写方法。在printf向显示器输出的过程中，sys_write函数会调用rw_char函数，传入设备号4（对应于/dev/tty0）以及要写入的字符串。

到目前为止，操作系统根据设备文件的inode结构体提供的信息，进行了分支，并通过设备号信息跳转到相应的设备驱动程序执行
![](attachment/9a986e22ba33aa2f07fb537819658b5d.png)
![](attachment/4558f12f037760ce42478fc1c563f99a.png)
![](attachment/f1c8bb9ffed9738a412d85eba74d5094.png)
### tty_write函数与con_write函数
`rw_ttyx`根据传入的rw (值为write) 参数进行分支，调用`tty_write`函数，该函数先判断输出缓冲区是否满，如果满了则先sleep该进程，反之将字符串放入输出缓冲区中，最后调用`tty->write`函数进行输出。tty_write函数通过调用tty->write方法将字符串传递给con_write函数，con_write函数执行最终的输出显示器操作，它处理字符串输出到显示器的具体细节。它将字符串中的每个字符发送到视频内存（显存），并根据需要更新光标位置。当字符串全部写入显存后，显示器将自动显示更新后的内容。对于简单的文本输出，如使用printf函数，显示器不会向CPU发出中断。
![](attachment/f1c8bb9ffed9738a412d85eba74d5094.png)![](attachment/f1c8bb9ffed9738a412d85eba74d5094.png)
![](attachment/990a158e557216d612b143f9269cceb8.png)
**旁注: **在Linux和类Unix操作系统中，设备通常分为两类：字符设备和块设备。这两种类型的设备在数据访问方式和操作模式上有显著的区别。

1. 字符设备： 字符设备是基于字节流的设备，这意味着它们以顺序方式处理数据，一个字节接一个字节。对于这些设备，用户可以直接读写数据，无需考虑数据在设备中的实际存储位置。字符设备的典型例子包括终端（如tty设备）、串行端口以及其他一些硬件接口。在Linux中，字符设备通常在/dev目录下以设备文件的形式表示。
2. 块设备： 块设备是基于数据块的设备，这意味着它们处理固定大小的数据块，而不是字节流。块设备通常用于存储大量数据，例如硬盘驱动器、闪存设备和CD-ROM驱动器。与字符设备不同，块设备的读写操作需要考虑数据在设备中的实际存储位置，因为它们允许随机访问数据块。在Linux中，块设备同样位于/dev目录下，以设备文件的形式表示。

总之，字符设备和块设备是两种不同类型的设备，它们在数据访问方式和操作模式上有显著的区别。字符设备基于字节流，处理数据的方式是顺序的，而块设备基于数据块，允许随机访问数据。在Linux操作系统中，这两种类型的设备都在/dev目录下以设备文件的形式表示。
## 用键盘输入
键盘输入是一个中断事件

1. 当按下键盘时，键盘控制器会检测到按键事件，并将扫描码（Scan Code）存储在其内部缓冲区中，键盘控制器向键盘发送中断请求信号。
2. CPU检测到IRQ1中断信号，并暂停当前执行的任务，根据IRQ找到并执行相应的中断处理程序`_keyboard_interrupt`，该程序从键盘控制器的数据端口0x60处读取其内部缓冲区的数据

![](attachment/990a158e557216d612b143f9269cceb8.png)

3. keyboard_interrupt 被调用后，会将键盘扫描码做为下标，调用key_table函数数组中保存的与该按键对应的响应函数，响应函数通过key_map找到相应的字符ascill码

![](attachment/a1984fc0ae5d3f224966bb4c15b2e0ea.png)

4. 在将扫描码转换为ASCII字符后，keyboard_interrupt会处理特殊按键（如Shift、Ctrl、Alt等）和组合键，然后将最终的字符放入输入缓冲区read_q。

![](attachment/7244d292d962167035026ae6d17647cd.png)

5. 如果TTY设备的回显（echo）功能已启用，keyboard_interrupt会将字符发送给当前TTY设备的输出函数con_write。这个函数会将字符写入显存，从而在屏幕上显示该字符。

![](attachment/9bc6319e4399ae16eed295b023956965.png)
![](attachment/a1984fc0ae5d3f224966bb4c15b2e0ea.png)
旁注
> 什么是IRQ
> 硬件设备发送给 CPU 的中断请求信号（IRQ）通常是一个简单的电平信号，用于通知 CPU 有一个需要处理的中断事件。IRQ 信号的内容本身非常简单，它主要起到通知 CPU 的作用，而不包含详细的中断信息或指令。IRQ 信号能引发中断的原因在于 CPU 对这些信号的设计和处理方式。
> 当硬件设备需要 CPU 的注意时（例如读取数据、处理错误或通知状态改变），它会发送一个 IRQ 信号给 CPU。CPU 上有一些专用的引脚（称为中断请求引脚）用于接收这些信号。每个硬件设备通常都有一个与之关联的 IRQ 编号，用于在 CPU 和硬件设备之间进行识别。
> 收到 IRQ 信号后，CPU 会根据信号的优先级和当前状态来决定何时处理这个中断。在适当的时机，CPU 会暂停当前任务，然后查询中断向量表，找到与收到的 IRQ 编号对应的中断处理程序的地址，并跳转到该地址开始执行中断处理程序。
> IRQ 信号本身并不包含 int 指令或其他类似的处理器指令。实际上，IRQ 信号与处理器指令是分开的，它们只是用于通知 CPU 有一个需要处理的中断事件。处理器在接收到 IRQ 信号后，会根据内部逻辑和中断处理机制来执行相应的中断处理程序。

## 使用生磁盘
![](attachment/9bc6319e4399ae16eed295b023956965.png)
我们自下而上，逐步学习从生磁盘到文件视图的背后机制，现在我们忽略文件视图的封装，看进程如果要直接读写生磁盘，该怎么做
### 第1层抽象---盘块
CPU要向磁盘写入，那么先要确定目标扇区在磁盘中的的位置，那么就需要知道一个三维坐标信息，即磁道号(柱面号C)、磁头号(H)和扇区号(S)。有了这个信息，再执行out指令，就可以完成磁盘的写入了。由于这个坐标信息比较复杂，比进程来说很不友好，因此我们现在进行第一层抽象，即进程只传递盘块号给操作系统（实际上是设备驱动程序），由操作系统将这个盘块号转换为(C,H,S)的扇区坐标
![](attachment/9bc6319e4399ae16eed295b023956965.png)
盘块号是操作系统为了对磁盘进行第一层抽象而进行的第一层编址，因为同一进程使用盘块号相邻的盘块，而磁盘读写时间主要受寻道时间影响，因此编址后盘块号相邻的盘块最好处于同一磁道（这样就不用寻道了）。因此盘块由相邻的多个扇区组成，因此扇区号也遵循这个编址原则
![](attachment/3b8752aa64ad18267791470721e6da11.png)
**为什么要引入盘块号，而不是直接传递扇区号呢？**
启动磁盘读写是一个耗时的事情(寻道+旋转+传输)，因此应该尽可能多的在一次磁盘操作中多读取，这样读写速度也就更快(传输速度只占一次磁盘读写耗时的很小部分)。（在磁盘读写操作中，寻道时间和旋转延迟通常是磁盘读写时间中最耗时的部分。因此，在进行磁盘读写操作时，将更多的数据读入内存缓存中，并尽可能减少读写次数，可以最大程度地减少磁盘寻道和旋转时间的影响，提高磁盘读写的效率和速度。） 因此操作系统引入盘块的概念，**盘块（disk block）是文件系统管理磁盘空间的基本单位，文件系统通过盘块号来标识文件在磁盘上的位置**，而磁盘读写的基本单位是扇区。扇区是磁盘上最小可寻址的物理存储单元，而盘块是操作系统中逻辑上抽象的单位，其大小可以是多个扇区(512bytes)的整数倍
盘块大小越大，读写速度就会越快。这是因为，当操作系统需要读取一个文件时，在一次磁盘操作中它会将整个盘块读入内存，而不是一个个字节逐个读取。盘块越大，每次读取的数据就越多，这可以减少磁盘读写操作的次数，从而提高读写速度。
**为什么盘块越大，空间利用率越低？**
即使一个文件只有1KB的数据，因为盘块（disk block）是文件系统管理磁盘空间的基本单位，因此如果盘块大小为4KB，则它也会占用4KB的磁盘空间，剩余的3KB空间（内部碎片）就会浪费掉。因此，盘块越大，文件所占用的磁盘空间就会变大，但实际数据却变少，导致空间利用率降低。
![](attachment/91f8530d210c0afbc11dc7f156acc96b.png)
### 第2层抽象---请求队列
CPU执行进程的速度远快于磁盘读写，因此同一时间会存在多个未处理的磁盘读写请求 (这我们的语境中，这个请求是进程发出读写目标盘块号的请求)，因此要形成一个请求队列。再按照合理的调度算法处理这些请求
![](attachment/abe14f751c02e58f30a4e7a5a93ced04.png)

1. FCFS

效率低
![](attachment/d58b62057cba4063b2048411aa900d27.png)

2. SSTF

最少寻找时间优先，即离磁头最近的先处理，与进程调度的短作业优先算法类似，也会导致饥饿问题
![](attachment/0cb652a062d03a762e9aa2db9cce8ced.png)

3. Scan

扫描算法，不存在饥饿问题，但不公平，对中间的盘块号处理快于两边（中间的占便宜）
![](attachment/91f8530d210c0afbc11dc7f156acc96b.png)

4. C-Scan

电梯算法，在复位过程中不处理中间的盘块号，保证了公平性
![](attachment/bad850a635a87757a071d989bebb0ba5.png)
![](attachment/c75f8ca18d39ef3fddd1587ba8229288.png)
## 从字符流到磁盘块
现在我们在盘块号的基础上进一步抽象（第3层抽象），得到文件视图，文件在用户来看就是字符序列，一个字节接一个字节，用户可以处理这些字节数据而不用在乎数据的实际存储位置。
文件是用户角度的概念，它是由一系列字符组成的数据流。在文件被写入磁盘时，操作系统需要将字符流映射到磁盘块上，以便在需要时可以快速读取文件数据。
为了实现字符流到磁盘块的映射，文件系统通常会将一个文件分割成若干个固定大小的块，这些块被称为磁盘块。当一个文件被写入磁盘时，操作系统会将文件分割成若干个磁盘块，并将每个磁盘块映射到磁盘上的一个或多个扇区。
![](attachment/0cb652a062d03a762e9aa2db9cce8ced.png)
接下来讲述映射的几种方式
### 连续存储
连续存储是一种将文件连续地存储在磁盘上的方式。在连续存储方式下，文件被分为若干个大小相等的磁盘块，并且这些磁盘块在磁盘上是连续存储的。操作系统通过维护文件的起始位置和长度信息，可以快速地定位和读取整个文件。
连续存储的优点是读取速度快，但缺点是文件大小固定，不易扩展(可能会覆盖后续的文件)，且容易产生外部碎片。
![](attachment/0cb652a062d03a762e9aa2db9cce8ced.png)
### 链式存储
链式存储是一种将文件存储在多个不连续的磁盘块上的方式。在链式存储方式下，每个磁盘块除了存储文件数据外，还包含一个指向下一个磁盘块的指针。操作系统通过遍历磁盘块链表，可以读取整个文件。
链式存储的优点是文件大小可变，且可以避免外部碎片，但缺点是需要额外的指针开销，且读取速度比连续存储慢。
![](attachment/c75f8ca18d39ef3fddd1587ba8229288.png)
### 索引存储
索引存储是一种将文件的元数据和磁盘块的地址保存在**索引块**中的方式。在索引存储方式下，每个文件都对应一个或多个索引块(对大文件)，每个索引块中保存若干个磁盘块的地址。操作系统通过读取文件的索引块，可以快速地定位和读取文件。
索引存储的优点是可以快速定位和读取文件，且文件大小可变，但缺点是需要额外的索引块开销，且索引块也可能发生外部碎片。
![](attachment/2cf522c02b738c3a9a4c96c80234c33e.png)![](attachment/5a31bc2eac3f158a3ab27b9977767a41.png)
## 从字符流到磁盘块的实现
我们从sys_write出发，该函数通过3个参数信息（文件描述符fd, 内存缓冲区buffer, 计数count）完成了字符流到盘块的映射和目标盘块的修改
### 通过文件描述符fd找到inode
在本节开头已经讲过如何通过fd找到目标inode，主要是通过将文件描述符当做filp数组的索引，再通过文件表的映射，能够找到目标文件的inode。inode可以视为文件的FCB，它存储了文件的元数据(即文件的描述性信息，例如文件的名称、类型、大小、创建日期、修改日期、访问权限等,还包括索引块的信息)，sys_write用`S_ISREG(inode->i_mode)`检查目标文件的类型，如果是普通文件(而不是设备文件)，则调用file_write来执行具体的写入操作
![](attachment/fd5a4776cf86d89024df3cd3df72a1a8.png)
### file_write函数
![](attachment/0cb652a062d03a762e9aa2db9cce8ced.png)
file_write函数要想向完成对目标磁盘块的写入，那么它需要完成两件事情

1. 确定字符流的起点和终点

由参数`file`获取文件操作指针的开始位置，即字符流的起点。file是一个指向文件表条目的指针，通过它可以获取文件操作指针等信息。然后加上参数count便能获取字符流的终点。
看下图源码，`file_write`先查看文件的打开标志是否是追加(`O_APPEND`)，如果是则将待写入位置pos置为文件末尾(`i_size`)，否则置pos为文件当前偏移量（文件操作指针的开始位置）
![](attachment/35544cba9edd344712efa981d76f7912.png)

2. 确定目标盘块号

create_block返回目标盘块号，它利用了两个参数inode和pos/BLOCK_SIZE

1. inode参数：inode结构中包含了关于文件的元数据，如文件大小、权限等。更重要的是，它还包含了直接索引、间接索引、双间接索引和三间接索引指针，这些指针用于查找文件数据所在的磁盘块。**通过提供inode参数，create_block函数可以访问这些索引指针，从而找到和分配新的磁盘块。**
2. pos/block_size参数：pos/block_size表示文件中逻辑盘块号。这个信息对于**确定应该使用哪个索引级别**（直接索引、间接索引等）非常重要。例如，对于较小的文件，pos/block_size可能位于直接索引范围内，这意味着可以直接使用inode结构中的直接索引指针来访问数据盘块。而对于较大的文件，可能需要使用间接索引或更高级别的索引来查找数据盘块。通过传递pos/block_size参数，create_block函数可以根据文件操作指针和文件大小选择合适的索引级别，从而正确地分配和映射新的磁盘块。

![](attachment/bad850a635a87757a071d989bebb0ba5.png)

3. 执行读写操作

使用**bread函数读取盘块的数据**。bread负责将指定的盘块数据从磁盘读取到内存中。即将目的盘块号放入电梯队列后续内容就是生磁盘的使用了(算出C,H,S进行磁盘读写)
如果该盘块已经在内存缓冲区中，bread会直接返回指向该缓冲区的指针。否则，它会分配一个新的缓冲区，从磁盘读取数据，然后返回指针。每个盘块只进行一次磁盘读写操作，以下是读写count个字符的源码（这部分还是直接看linux0.11源码完全注释比较好🙏）
**旁注: 磁盘数据缓冲区**
> 磁盘块的**数据缓冲区**是操作系统用于在内存中暂时存储磁盘块数据的区域。当应用程序需要读取或写入磁盘块时，操作系统会将磁盘块的数据读取到缓冲区中，然后在缓冲区中进行读取或写入操作。这样可以减少磁盘I/O操作的次数，提高文件系统的性能。缓冲区还可以被用于实现文件系统的高级功能，如文件系统缓存和延迟写入等。

```c
while (i < count) {
    block = create_block(inode, pos / BLOCK_SIZE);
    bh = bread(inode->i_dev, block);//bh（缩写为buffer head）实际上是一个指向buffer_head结构的指针，而不是直接指向磁盘缓冲区。
                                    //buffer_head结构包含了关于磁盘缓冲区的信息，例如磁盘设备号、块号、脏标志等。
                                    //buffer_head结构中有一个成员变量b_data，这是一个指向实际磁盘缓冲区的指针。
    int c = pos % BLOCK_SIZE; 
    char *p = c + bh->b_data;
    bh->b_dirt = 1;
    c = BLOCK_SIZE - c;
    pos += c;

    while (c-- > 0) {
        *(p++) = get_fs_byte(buf++); // 将数据从源缓冲区（buf）拷贝到目标缓冲区（bh->b_data）。这个循环一次处理一个字节，直到当前盘块的数据被写满。
    }                               // 注意，这个循环并不涉及磁盘读写操作，因为bh->b_data指向的是磁盘在内存中的缓冲区。

    brelse(bh); // 在内层while循环结束后，brelse函数被调用以释放bh。这个函数会检查缓冲区是否被标记为脏（bh->b_dirt），
                // 如果是，则在适当的时机将数据写回磁盘。这意味着磁盘读写操作不会频繁发生，而是在数据准备好写回磁盘时进行。
}
filp->f_pos = pos;
```
![](attachment/35544cba9edd344712efa981d76f7912.png)
### 文件视图
对设备文件的inode存储着不同的信息，有主设备号，设备类型等，但在用户看来，无论是磁盘还是外设，均是以文件的形式展现，这也印证了那句linux哲学 
"Everything is a file"
![](attachment/f0ba7c8f2c72156377deff8ba877cfb1.png)
## 目录树
前面提到，我们用文件描述符fd获取相应文件的inode，程序中的fd是由sys_open系统调用返回得到的，而sys_open接受一个文件路径名作为参数，因此sys_open一定能完成这样一件事情: 根据文件路径名找到目标inode，为其创建一个文件表项，并返回一个文件描述符，用户可以通过这个文件描述符在后续操作中访问文件。
磁盘在用户看来，就是一个目录树，用户通过提供文件路径就可以访问目标文件。这得益于OS提供的第4层抽象，OS通过引入目录文件将整个磁盘抽象为目录树
![](attachment/f0ba7c8f2c72156377deff8ba877cfb1.png)![](attachment/2b35f973b51169eaec9bfb7f361896d5.png)
我们现在以查找`/my/data/a`为例讲述目录树背后的机制
目录树要完成的就是能够通过用户提供的路径名找到目标文件的inode, 后续找到目标磁盘块并写入的工作由前3层抽象完成。那么怎么找到inode呢？我们需要有一个根目录`‘/’`，在这个根目录文件对应的数据块下存放它所包含的子文件和子目录的目录项。目录项（directory entry）通常包含文件名和相应的 inode 号。为什么不直接在当前目录文件对应的数据块存放子目录的inode呢？因为这样会使得查找的成本高，载入不必要的数据，因此只存放文件名以供查找和inode号以获取下一级子目录的数据块
![](attachment/bad850a635a87757a071d989bebb0ba5.png)
于是我们用find_entry函数在根目录文件的数据块上逐个寻找与`my`匹配的目录项，并通过这个目录项获取到目录文件my的inode号。接着，我们使用 iget 函数根据找到的 inode 号在inode数组中获取相应的inode。对每一级目录，我们不断执行这个过程，首先在根目录中查找 my，然后在 my 目录中查找 data，最后在 data目录中查找 file。每一步都需要使用 find_entry 和 iget 函数来获取相应的目录项和 inode 结构。
![](attachment/2b35f973b51169eaec9bfb7f361896d5.png)
**旁注： inode数组**
> 在磁盘上，inode 以数组的形式组织。这个数组被称为 inode 表。inode 表中的每个元素都是一个固定大小的 inode 结构。文件系统中的每个文件和目录都有一个唯一的 inode 号，用于在 inode 表中定位其对应的 inode 结构。inode 号从 1 开始（注意，inode 号 0 是保留的，不表示任何文件或目录）。
> 当需要访问一个文件或目录的元数据时，首先需要从磁盘上的 inode 数组（即 inode 表）中读取相应的 inode 结构。

![](attachment/2b35f973b51169eaec9bfb7f361896d5.png)![](attachment/2cf522c02b738c3a9a4c96c80234c33e.png)
![](attachment/2cf522c02b738c3a9a4c96c80234c33e.png)
